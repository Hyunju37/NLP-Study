{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Practice 5 - Parameter Efficient Tunning (ALBERT, DistillBERT) & Prompt Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:54:53.324253Z",
     "iopub.status.busy": "2024-06-23T05:54:53.323619Z",
     "iopub.status.idle": "2024-06-23T05:54:54.375289Z",
     "shell.execute_reply": "2024-06-23T05:54:54.374283Z",
     "shell.execute_reply.started": "2024-06-23T05:54:53.324221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['부산', '행', '때문', '너무', '기대하고', '봤'], ['한국', '좀비', '영화', '어색하지', '않게', '만들어졌', '놀랍']]\n",
      "(0, 1)\n",
      "165384\n",
      "165384\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/input/2024-1-nlp-5/Korean_movie_reviews_2016.txt/Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
    "    texts, labels = zip(*docs)\n",
    "\n",
    "words_list = [doc.strip().split() for doc in texts]\n",
    "print(words_list[:2])\n",
    "print(labels[:2])\n",
    "print(len(texts))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:54:56.630738Z",
     "iopub.status.busy": "2024-06-23T05:54:56.630380Z",
     "iopub.status.idle": "2024-06-23T05:54:56.637569Z",
     "shell.execute_reply": "2024-06-23T05:54:56.636660Z",
     "shell.execute_reply.started": "2024-06-23T05:54:56.630711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, tuple)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts), type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:54:59.578514Z",
     "iopub.status.busy": "2024-06-23T05:54:59.578162Z",
     "iopub.status.idle": "2024-06-23T05:55:11.866626Z",
     "shell.execute_reply": "2024-06-23T05:55:11.865767Z",
     "shell.execute_reply.started": "2024-06-23T05:54:59.578485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 05:55:01.233083: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-23 05:55:01.233198: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-23 05:55:01.362069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_one_hot = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:55:14.782589Z",
     "iopub.status.busy": "2024-06-23T05:55:14.781955Z",
     "iopub.status.idle": "2024-06-23T05:55:15.301426Z",
     "shell.execute_reply": "2024-06-23T05:55:15.300370Z",
     "shell.execute_reply.started": "2024-06-23T05:55:14.782556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(texts, y_one_hot, test_size=0.2, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_remain, y_remain, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:55:35.654670Z",
     "iopub.status.busy": "2024-06-23T05:55:35.654285Z",
     "iopub.status.idle": "2024-06-23T05:55:35.661120Z",
     "shell.execute_reply": "2024-06-23T05:55:35.660307Z",
     "shell.execute_reply.started": "2024-06-23T05:55:35.654641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132307, 132307, 16538, 16538, 16539, 16539)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train),len(X_val),len(y_val),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:30:19.495903Z",
     "iopub.status.busy": "2024-06-23T02:30:19.495382Z",
     "iopub.status.idle": "2024-06-23T02:30:19.504025Z",
     "shell.execute_reply": "2024-06-23T02:30:19.502630Z",
     "shell.execute_reply.started": "2024-06-23T02:30:19.495864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정말 이런 영화 보는 시간 넘아 깝 고통스러웠 영화 보고 아팠'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:30:21.020560Z",
     "iopub.status.busy": "2024-06-23T02:30:21.019462Z",
     "iopub.status.idle": "2024-06-23T02:30:21.029473Z",
     "shell.execute_reply": "2024-06-23T02:30:21.028275Z",
     "shell.execute_reply.started": "2024-06-23T02:30:21.020522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X_train : string으로 이루어진 list\n",
    "# y_train : numpy.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 5.1 - Parameter Efficient Tuning with ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer & Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:57:07.161396Z",
     "iopub.status.busy": "2024-06-23T04:57:07.160712Z",
     "iopub.status.idle": "2024-06-23T04:57:07.655550Z",
     "shell.execute_reply": "2024-06-23T04:57:07.654483Z",
     "shell.execute_reply.started": "2024-06-23T04:57:07.161363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c36d2a50b3496a81891e820a5feb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f2ee8e0c9483ab60c10198df65f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFAlbertForSequenceClassification, AlbertForSequenceClassification\n",
    "tokenizer= BertTokenizer.from_pretrained(\"kykim/albert-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:57:11.045364Z",
     "iopub.status.busy": "2024-06-23T04:57:11.044759Z",
     "iopub.status.idle": "2024-06-23T04:58:08.204798Z",
     "shell.execute_reply": "2024-06-23T04:58:08.203590Z",
     "shell.execute_reply.started": "2024-06-23T04:57:11.045333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_val_tokenized = tokenizer(X_val, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_test_tokenized = tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:31:34.471900Z",
     "iopub.status.busy": "2024-06-23T02:31:34.471467Z",
     "iopub.status.idle": "2024-06-23T02:31:34.480362Z",
     "shell.execute_reply": "2024-06-23T02:31:34.478905Z",
     "shell.execute_reply.started": "2024-06-23T02:31:34.471867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:31:38.469879Z",
     "iopub.status.busy": "2024-06-23T02:31:38.469439Z",
     "iopub.status.idle": "2024-06-23T02:31:38.477775Z",
     "shell.execute_reply": "2024-06-23T02:31:38.476150Z",
     "shell.execute_reply.started": "2024-06-23T02:31:38.469842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:31:40.895807Z",
     "iopub.status.busy": "2024-06-23T02:31:40.895429Z",
     "iopub.status.idle": "2024-06-23T02:31:40.903614Z",
     "shell.execute_reply": "2024-06-23T02:31:40.902355Z",
     "shell.execute_reply.started": "2024-06-23T02:31:40.895777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(X_train_tokenized.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:31:59.122991Z",
     "iopub.status.busy": "2024-06-23T02:31:59.122594Z",
     "iopub.status.idle": "2024-06-23T02:31:59.131628Z",
     "shell.execute_reply": "2024-06-23T02:31:59.130500Z",
     "shell.execute_reply.started": "2024-06-23T02:31:59.122952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2, 14038, 14119, 14632, 15024, 14084,  2866,  8095,  2506,\n",
       "       20279, 14233,  8258, 14632, 14221, 28733,     3,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:32:01.279945Z",
     "iopub.status.busy": "2024-06-23T02:32:01.276414Z",
     "iopub.status.idle": "2024-06-23T02:32:01.293094Z",
     "shell.execute_reply": "2024-06-23T02:32:01.291708Z",
     "shell.execute_reply.started": "2024-06-23T02:32:01.279871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132307, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:32:03.652566Z",
     "iopub.status.busy": "2024-06-23T02:32:03.652091Z",
     "iopub.status.idle": "2024-06-23T02:32:03.660539Z",
     "shell.execute_reply": "2024-06-23T02:32:03.659200Z",
     "shell.execute_reply.started": "2024-06-23T02:32:03.652462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized['token_type_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:32:06.040764Z",
     "iopub.status.busy": "2024-06-23T02:32:06.039750Z",
     "iopub.status.idle": "2024-06-23T02:32:06.049031Z",
     "shell.execute_reply": "2024-06-23T02:32:06.047712Z",
     "shell.execute_reply.started": "2024-06-23T02:32:06.040692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:32:08.334508Z",
     "iopub.status.busy": "2024-06-23T02:32:08.334125Z",
     "iopub.status.idle": "2024-06-23T02:32:08.341841Z",
     "shell.execute_reply": "2024-06-23T02:32:08.340553Z",
     "shell.execute_reply.started": "2024-06-23T02:32:08.334477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132307"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:32:11.014046Z",
     "iopub.status.busy": "2024-06-23T02:32:11.013598Z",
     "iopub.status.idle": "2024-06-23T02:32:11.022098Z",
     "shell.execute_reply": "2024-06-23T02:32:11.020678Z",
     "shell.execute_reply.started": "2024-06-23T02:32:11.014012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tokenized['input_ids']), type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:58:22.809408Z",
     "iopub.status.busy": "2024-06-23T04:58:22.808810Z",
     "iopub.status.idle": "2024-06-23T04:58:23.077974Z",
     "shell.execute_reply": "2024-06-23T04:58:23.076971Z",
     "shell.execute_reply.started": "2024-06-23T04:58:22.809374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at kykim/albert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow based!!\n",
    "#albert_model = TFAlbertForSequenceClassification.from_pretrained(\"kykim/albert-kor-base\", num_labels=2, from_pt=True)\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained(\"kykim/albert-kor-base\", num_labels=2)\n",
    "#albert_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 및 과제 5.1\n",
    "\n",
    "Finetune your ALBERT model with \"Korean_movie_reviews_2016.txt\" 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#X_train_tokenized.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T11:20:41.712505Z",
     "iopub.status.busy": "2024-06-22T11:20:41.711857Z",
     "iopub.status.idle": "2024-06-22T11:20:41.718457Z",
     "shell.execute_reply": "2024-06-22T11:20:41.717530Z",
     "shell.execute_reply.started": "2024-06-22T11:20:41.712477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:56:50.817628Z",
     "iopub.status.busy": "2024-06-23T05:56:50.816958Z",
     "iopub.status.idle": "2024-06-23T05:56:50.824035Z",
     "shell.execute_reply": "2024-06-23T05:56:50.822916Z",
     "shell.execute_reply.started": "2024-06-23T05:56:50.817587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def make_dataset(tokenizer_output, y):\n",
    "    dataset_df = []\n",
    "    for idx, sample in enumerate(tokenizer_output['input_ids']):\n",
    "        row = [sample,tokenizer_output['token_type_ids'][idx],tokenizer_output['attention_mask'][idx],y[idx]]\n",
    "        dataset_df.append(row)\n",
    "    dataset_df = pd.DataFrame(dataset_df, \n",
    "                                columns=['input_ids','token_type_ids','attention_mask','label'])\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:58:33.788696Z",
     "iopub.status.busy": "2024-06-23T04:58:33.788296Z",
     "iopub.status.idle": "2024-06-23T04:58:34.320168Z",
     "shell.execute_reply": "2024-06-23T04:58:34.315923Z",
     "shell.execute_reply.started": "2024-06-23T04:58:33.788664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_df = make_dataset(X_train_tokenized, y_train)\n",
    "val_dataset_df = make_dataset(X_val_tokenized, y_val)\n",
    "test_dataset_df = make_dataset(X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T11:34:27.263318Z",
     "iopub.status.busy": "2024-06-22T11:34:27.262934Z",
     "iopub.status.idle": "2024-06-22T11:34:27.297048Z",
     "shell.execute_reply": "2024-06-22T11:34:27.296148Z",
     "shell.execute_reply.started": "2024-06-22T11:34:27.263279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:57:02.016413Z",
     "iopub.status.busy": "2024-06-23T05:57:02.016055Z",
     "iopub.status.idle": "2024-06-23T05:57:03.059522Z",
     "shell.execute_reply": "2024-06-23T05:57:03.058532Z",
     "shell.execute_reply.started": "2024-06-23T05:57:02.016387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "#print('to_tf_dataset' in dir(Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:58:38.320559Z",
     "iopub.status.busy": "2024-06-23T04:58:38.319892Z",
     "iopub.status.idle": "2024-06-23T04:58:39.288490Z",
     "shell.execute_reply": "2024-06-23T04:58:39.287395Z",
     "shell.execute_reply.started": "2024-06-23T04:58:38.320525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset_df)\n",
    "val_dataset = Dataset.from_pandas(val_dataset_df)\n",
    "test_dataset = Dataset.from_pandas(test_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:58:42.653220Z",
     "iopub.status.busy": "2024-06-23T04:58:42.652497Z",
     "iopub.status.idle": "2024-06-23T04:58:42.661568Z",
     "shell.execute_reply": "2024-06-23T04:58:42.660556Z",
     "shell.execute_reply.started": "2024-06-23T04:58:42.653188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 132307\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 16538\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 16539\n",
       " }))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids','token_type_ids','attention_mask'],\n",
    "    label_cols=[\"label\"],\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "#train_dataset = train_dataset.batch(64)\n",
    "#test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import Adam\n",
    "optimizer = tf.optimizers.Adam(learning_rate=5e-5)\n",
    "albert_model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = albert_model.compute_loss,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = albert_model.fit(train_dataset,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T12:48:33.999396Z",
     "iopub.status.busy": "2024-06-22T12:48:33.999009Z",
     "iopub.status.idle": "2024-06-22T12:48:34.532370Z",
     "shell.execute_reply": "2024-06-22T12:48:34.531454Z",
     "shell.execute_reply.started": "2024-06-22T12:48:33.999369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(val_result):\n",
    "    #metric = load_metric(\"accuracy\")\n",
    "    \n",
    "    labels = np.argmax(val_result.label_ids,axis=1)\n",
    "    preds = np.argmax(val_result.predictions,axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\":acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:58:56.479357Z",
     "iopub.status.busy": "2024-06-23T04:58:56.478374Z",
     "iopub.status.idle": "2024-06-23T04:58:56.529337Z",
     "shell.execute_reply": "2024-06-23T04:58:56.528183Z",
     "shell.execute_reply.started": "2024-06-23T04:58:56.479313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"albert_model\",\n",
    "                                  num_train_epochs=2,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  per_device_eval_batch_size= 32,\n",
    "                                  weight_decay = 0.01,\n",
    "                                 evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer_albert = Trainer(\n",
    "    model=albert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "#compute_metrics=compute_metrics,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:59:00.728631Z",
     "iopub.status.busy": "2024-06-23T04:59:00.728286Z",
     "iopub.status.idle": "2024-06-23T05:15:37.142326Z",
     "shell.execute_reply": "2024-06-23T05:15:37.141445Z",
     "shell.execute_reply.started": "2024-06-23T04:59:00.728605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8270' max='8270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8270/8270 16:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>0.215145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.208819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8270, training_loss=0.2198015930286486, metrics={'train_runtime': 995.8272, 'train_samples_per_second': 265.723, 'train_steps_per_second': 8.305, 'total_flos': 370533533151600.0, 'train_loss': 0.2198015930286486, 'epoch': 2.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_albert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:08:37.646409Z",
     "iopub.status.busy": "2024-06-22T13:08:37.645668Z",
     "iopub.status.idle": "2024-06-22T13:08:37.652999Z",
     "shell.execute_reply": "2024-06-22T13:08:37.651973Z",
     "shell.execute_reply.started": "2024-06-22T13:08:37.646377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:10:40.669452Z",
     "iopub.status.busy": "2024-06-22T13:10:40.668744Z",
     "iopub.status.idle": "2024-06-22T13:10:41.043056Z",
     "shell.execute_reply": "2024-06-22T13:10:41.041982Z",
     "shell.execute_reply.started": "2024-06-22T13:10:40.669419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.array(val_dataset['input_ids'][0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:22:25.192399Z",
     "iopub.status.busy": "2024-06-22T13:22:25.192004Z",
     "iopub.status.idle": "2024-06-22T13:22:25.200887Z",
     "shell.execute_reply": "2024-06-22T13:22:25.199921Z",
     "shell.execute_reply.started": "2024-06-22T13:22:25.192369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(val_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:15:21.161875Z",
     "iopub.status.busy": "2024-06-22T13:15:21.161514Z",
     "iopub.status.idle": "2024-06-22T13:15:21.173099Z",
     "shell.execute_reply": "2024-06-22T13:15:21.172003Z",
     "shell.execute_reply.started": "2024-06-22T13:15:21.161847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:38:03.343769Z",
     "iopub.status.busy": "2024-06-22T13:38:03.343410Z",
     "iopub.status.idle": "2024-06-22T13:38:03.354770Z",
     "shell.execute_reply": "2024-06-22T13:38:03.352926Z",
     "shell.execute_reply.started": "2024-06-22T13:38:03.343742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.Tensor(val_dataset[0]['input_ids']).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:35:24.373881Z",
     "iopub.status.busy": "2024-06-22T13:35:24.373515Z",
     "iopub.status.idle": "2024-06-22T13:35:24.382081Z",
     "shell.execute_reply": "2024-06-22T13:35:24.381054Z",
     "shell.execute_reply.started": "2024-06-22T13:35:24.373852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.array(val_dataset[0]['input_ids']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:41:59.623685Z",
     "iopub.status.busy": "2024-06-22T13:41:59.622904Z",
     "iopub.status.idle": "2024-06-22T13:41:59.629251Z",
     "shell.execute_reply": "2024-06-22T13:41:59.628084Z",
     "shell.execute_reply.started": "2024-06-22T13:41:59.623657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:42:01.262996Z",
     "iopub.status.busy": "2024-06-22T13:42:01.262142Z",
     "iopub.status.idle": "2024-06-22T13:42:01.268884Z",
     "shell.execute_reply": "2024-06-22T13:42:01.267839Z",
     "shell.execute_reply.started": "2024-06-22T13:42:01.262965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def drop_label(sample):\n",
    "    without_label = {k:torch.LongTensor(sample[k]).unsqueeze(0).to(device) for k in sample if k != 'label'}\n",
    "    return without_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:42:03.166439Z",
     "iopub.status.busy": "2024-06-22T13:42:03.166068Z",
     "iopub.status.idle": "2024-06-22T13:42:03.175075Z",
     "shell.execute_reply": "2024-06-22T13:42:03.174119Z",
     "shell.execute_reply.started": "2024-06-22T13:42:03.166411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "drop_label(val_dataset[0])['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T13:47:50.992455Z",
     "iopub.status.busy": "2024-06-22T13:47:50.991998Z",
     "iopub.status.idle": "2024-06-22T13:47:51.015729Z",
     "shell.execute_reply": "2024-06-22T13:47:51.014743Z",
     "shell.execute_reply.started": "2024-06-22T13:47:50.992425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#import torch.LongTensor\n",
    "output = albert_model(**(drop_label(val_dataset[200])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:08:25.691664Z",
     "iopub.status.busy": "2024-06-22T14:08:25.691322Z",
     "iopub.status.idle": "2024-06-22T14:08:25.702035Z",
     "shell.execute_reply": "2024-06-22T14:08:25.701153Z",
     "shell.execute_reply.started": "2024-06-22T14:08:25.691640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.argmax(torch.Tensor(val_dataset[200]['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:08:43.599813Z",
     "iopub.status.busy": "2024-06-22T14:08:43.598967Z",
     "iopub.status.idle": "2024-06-22T14:08:43.608796Z",
     "shell.execute_reply": "2024-06-22T14:08:43.607679Z",
     "shell.execute_reply.started": "2024-06-22T14:08:43.599776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.argmax(output.logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:10:34.108151Z",
     "iopub.status.busy": "2024-06-22T14:10:34.107337Z",
     "iopub.status.idle": "2024-06-22T14:10:54.957446Z",
     "shell.execute_reply": "2024-06-22T14:10:54.956343Z",
     "shell.execute_reply.started": "2024-06-22T14:10:34.108118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_result = trainer_albert.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:25:58.166069Z",
     "iopub.status.busy": "2024-06-22T14:25:58.165711Z",
     "iopub.status.idle": "2024-06-22T14:25:58.172130Z",
     "shell.execute_reply": "2024-06-22T14:25:58.171223Z",
     "shell.execute_reply.started": "2024-06-22T14:25:58.166041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "answers = np.argmax(val_result.label_ids,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:23:25.006994Z",
     "iopub.status.busy": "2024-06-22T14:23:25.006298Z",
     "iopub.status.idle": "2024-06-22T14:23:25.012624Z",
     "shell.execute_reply": "2024-06-22T14:23:25.011539Z",
     "shell.execute_reply.started": "2024-06-22T14:23:25.006959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_preds = np.argmax(val_result.predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:43:03.752445Z",
     "iopub.status.busy": "2024-06-22T14:43:03.751686Z",
     "iopub.status.idle": "2024-06-22T14:43:03.761840Z",
     "shell.execute_reply": "2024-06-22T14:43:03.760751Z",
     "shell.execute_reply.started": "2024-06-22T14:43:03.752414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(answers,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:34:17.245334Z",
     "iopub.status.busy": "2024-06-23T03:34:17.244950Z",
     "iopub.status.idle": "2024-06-23T03:34:17.253295Z",
     "shell.execute_reply": "2024-06-23T03:34:17.252294Z",
     "shell.execute_reply.started": "2024-06-23T03:34:17.245304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\",ax=ax,colorbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(dict(X_test_tokenized), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_preds = model.predict(dict(X_test_tokenized))\n",
    "#prediction_probs = tf.nn.softmax(y_preds.logits,axis=1).numpy()\n",
    "#y_predictions = np.argmax(prediction_probs, axis=1)\n",
    "#y_test = np.argmax(y_test, axis=1)\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T14:51:54.802566Z",
     "iopub.status.busy": "2024-06-22T14:51:54.801741Z",
     "iopub.status.idle": "2024-06-22T14:52:15.730490Z",
     "shell.execute_reply": "2024-06-22T14:52:15.729384Z",
     "shell.execute_reply.started": "2024-06-22T14:51:54.802537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_result = trainer_albert.predict(val_dataset)\n",
    "answers = np.argmax(val_result.label_ids,axis=1)\n",
    "y_preds = np.argmax(val_result.predictions,axis=1)\n",
    "accuracy_score(answers,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T15:00:03.585117Z",
     "iopub.status.busy": "2024-06-22T15:00:03.584316Z",
     "iopub.status.idle": "2024-06-22T15:00:03.715487Z",
     "shell.execute_reply": "2024-06-22T15:00:03.714433Z",
     "shell.execute_reply.started": "2024-06-22T15:00:03.585088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(answers,y_preds,['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T15:03:23.921417Z",
     "iopub.status.busy": "2024-06-22T15:03:23.920777Z",
     "iopub.status.idle": "2024-06-22T15:03:44.727874Z",
     "shell.execute_reply": "2024-06-22T15:03:44.720278Z",
     "shell.execute_reply.started": "2024-06-22T15:03:23.921387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_result = trainer_albert.predict(test_dataset)\n",
    "answers = np.argmax(test_result.label_ids,axis=1)\n",
    "y_preds = np.argmax(test_result.predictions,axis=1)\n",
    "accuracy_score(answers,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T15:03:57.107758Z",
     "iopub.status.busy": "2024-06-22T15:03:57.106919Z",
     "iopub.status.idle": "2024-06-22T15:03:57.231480Z",
     "shell.execute_reply": "2024-06-22T15:03:57.230463Z",
     "shell.execute_reply.started": "2024-06-22T15:03:57.107724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(answers,y_preds,['negative','positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 5.2 - Parameter Efficient Tuning with DistillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:52:12.711635Z",
     "iopub.status.busy": "2024-06-23T02:52:12.710798Z",
     "iopub.status.idle": "2024-06-23T02:52:59.249879Z",
     "shell.execute_reply": "2024-06-23T02:52:59.248706Z",
     "shell.execute_reply.started": "2024-06-23T02:52:12.711600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4d0a449c8e47b98d7059d946a537ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6715e8ccfb74471fb896c09393356d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c578e7722244978c9f8f4a0ee944a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "\n",
    "tokenizer= BertTokenizer.from_pretrained(\"monologg/distilkobert\") #바꿔야함 distilkobert monologg/distilkobert\n",
    "X_train_tokenized = tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_val_tokenized = tokenizer(X_val, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_test_tokenized = tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:13.402610Z",
     "iopub.status.busy": "2024-06-23T02:53:13.402241Z",
     "iopub.status.idle": "2024-06-23T02:53:14.173021Z",
     "shell.execute_reply": "2024-06-23T02:53:14.172042Z",
     "shell.execute_reply.started": "2024-06-23T02:53:13.402580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_df = make_dataset(X_train_tokenized, y_train)\n",
    "val_dataset_df = make_dataset(X_val_tokenized, y_val)\n",
    "test_dataset_df = make_dataset(X_test_tokenized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:16.266026Z",
     "iopub.status.busy": "2024-06-23T02:53:16.265504Z",
     "iopub.status.idle": "2024-06-23T02:53:17.816362Z",
     "shell.execute_reply": "2024-06-23T02:53:17.815185Z",
     "shell.execute_reply.started": "2024-06-23T02:53:16.265994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "train_dataset = Dataset.from_pandas(train_dataset_df)\n",
    "val_dataset = Dataset.from_pandas(val_dataset_df)\n",
    "test_dataset = Dataset.from_pandas(test_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:20.088753Z",
     "iopub.status.busy": "2024-06-23T02:53:20.088053Z",
     "iopub.status.idle": "2024-06-23T02:53:20.094610Z",
     "shell.execute_reply": "2024-06-23T02:53:20.093698Z",
     "shell.execute_reply.started": "2024-06-23T02:53:20.088714Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 132307\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 16538\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 16539\n",
       " }))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:25.238489Z",
     "iopub.status.busy": "2024-06-23T02:53:25.237614Z",
     "iopub.status.idle": "2024-06-23T02:53:27.074412Z",
     "shell.execute_reply": "2024-06-23T02:53:27.073644Z",
     "shell.execute_reply.started": "2024-06-23T02:53:25.238460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e10409f4f3e4c48be0d16a81fed0304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "model_distilBERT = DistilBertForSequenceClassification.from_pretrained(\"monologg/distilkobert\", num_labels=2)\n",
    "#model_distillBERT.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 및 과제 5.2 \n",
    "\n",
    "Finetune your DistilKoBERT model with \"Korean_movie_reviews_2016.txt\" 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:30.414614Z",
     "iopub.status.busy": "2024-06-23T02:53:30.414274Z",
     "iopub.status.idle": "2024-06-23T02:53:31.311980Z",
     "shell.execute_reply": "2024-06-23T02:53:31.311024Z",
     "shell.execute_reply.started": "2024-06-23T02:53:30.414586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"distilbert_model\",\n",
    "                                  num_train_epochs=2,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  per_device_eval_batch_size= 32,\n",
    "                                  weight_decay = 0.01,\n",
    "                                 evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer_distilbert = Trainer(\n",
    "    model=model_distilBERT,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:53:35.509708Z",
     "iopub.status.busy": "2024-06-23T02:53:35.508767Z",
     "iopub.status.idle": "2024-06-23T02:59:16.723965Z",
     "shell.execute_reply": "2024-06-23T02:59:16.723000Z",
     "shell.execute_reply.started": "2024-06-23T02:53:35.509647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240623_025343-crk9mjwn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyunju/huggingface/runs/crk9mjwn' target=\"_blank\">distilbert_model</a></strong> to <a href='https://wandb.ai/hyunju/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyunju/huggingface' target=\"_blank\">https://wandb.ai/hyunju/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyunju/huggingface/runs/crk9mjwn' target=\"_blank\">https://wandb.ai/hyunju/huggingface/runs/crk9mjwn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8270' max='8270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8270/8270 05:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.479298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.480500</td>\n",
       "      <td>0.471628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8270, training_loss=0.49993628855916294, metrics={'train_runtime': 340.8191, 'train_samples_per_second': 776.406, 'train_steps_per_second': 24.265, 'total_flos': 1041073707446640.0, 'train_loss': 0.49993628855916294, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_distilbert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:49:40.915910Z",
     "iopub.status.busy": "2024-06-23T03:49:40.915425Z",
     "iopub.status.idle": "2024-06-23T03:49:46.903706Z",
     "shell.execute_reply": "2024-06-23T03:49:46.902799Z",
     "shell.execute_reply.started": "2024-06-23T03:49:40.915877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7642399322771798"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "val_result = trainer_distilbert.predict(val_dataset)\n",
    "answers = np.argmax(val_result.label_ids,axis=1)\n",
    "y_preds = np.argmax(val_result.predictions,axis=1)\n",
    "accuracy_score(answers,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:50:13.141498Z",
     "iopub.status.busy": "2024-06-23T03:50:13.140855Z",
     "iopub.status.idle": "2024-06-23T03:50:13.353120Z",
     "shell.execute_reply": "2024-06-23T03:50:13.351881Z",
     "shell.execute_reply.started": "2024-06-23T03:50:13.141465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAIjCAYAAAAHj8HUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEQklEQVR4nO3deVhV1f7H8c8BZB4dcUBQURIzzUY0RVPT1HIoh8REE83KsTS1ropT3ixz6qZl5RSWlUOZdnPK2cwhh9IcULNyTAVEBBH27w9/ntsRNEgQXL1fz8PzuNdee63vPo/Ah73XPsdmWZYlAAAAgzkVdAEAAAD5jcADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAOgUDpw4IAeeeQR+fn5yWazadGiRXk6/pEjR2Sz2TRz5sw8Hfd2Vr9+fdWvX7+gywDyBYEHwHXFx8fr2WefVcWKFeXu7i5fX1/VqVNHkyZN0sWLF/N17ujoaO3evVtjxozRnDlzdO+99+brfLdSly5dZLPZ5Ovrm+3reODAAdlsNtlsNr355pu5Hv/YsWOKjY3Vjh078qBawAwuBV0AgMJpyZIlatu2rdzc3NS5c2fdeeedunTpktavX6+BAwfqp59+0nvvvZcvc1+8eFGbNm3Sq6++ql69euXLHMHBwbp48aKKFCmSL+P/FRcXF6WkpGjx4sVq166dw764uDi5u7srNTX1b4197NgxjRgxQiEhIapZs2aOj1u2bNnfmg+4HRB4AGRx+PBhdejQQcHBwVq1apVKly5t3/fCCy/o4MGDWrJkSb7Nf/r0aUmSv79/vs1hs9nk7u6eb+P/FTc3N9WpU0cff/xxlsAzd+5cNW/eXPPnz78ltaSkpMjT01Ourq63ZD6gIHBLC0AW48aNU3Jysj744AOHsHNVaGio+vbta9++fPmyRo0apUqVKsnNzU0hISF65ZVXlJaW5nBcSEiIWrRoofXr1+v++++Xu7u7KlasqNmzZ9v7xMbGKjg4WJI0cOBA2Ww2hYSESLpyK+jqv/8sNjZWNpvNoW358uV66KGH5O/vL29vb4WFhemVV16x77/eGp5Vq1apbt268vLykr+/v1q2bKm9e/dmO9/BgwfVpUsX+fv7y8/PT127dlVKSsr1X9hrdOzYUV9//bUSEhLsbVu2bNGBAwfUsWPHLP3Pnj2rAQMGqHr16vL29pavr68effRR7dy5095n9erVuu+++yRJXbt2td8au3qe9evX15133qlt27apXr168vT0tL8u167hiY6Olru7e5bzb9KkiQICAnTs2LEcnytQ0Ag8ALJYvHixKlasqNq1a+eof0xMjIYNG6ZatWppwoQJioyM1NixY9WhQ4csfQ8ePKgnn3xSjRs31vjx4xUQEKAuXbrop59+kiS1adNGEyZMkCQ99dRTmjNnjiZOnJir+n/66Se1aNFCaWlpGjlypMaPH6/HH39cGzZsuOFxK1asUJMmTXTq1CnFxsbqxRdf1MaNG1WnTh0dOXIkS/927drp/PnzGjt2rNq1a6eZM2dqxIgROa6zTZs2stlsWrBggb1t7ty5uuOOO1SrVq0s/Q8dOqRFixapRYsWeuuttzRw4EDt3r1bkZGR9vBRtWpVjRw5UpLUo0cPzZkzR3PmzFG9evXs45w5c0aPPvqoatasqYkTJ6pBgwbZ1jdp0iSVKFFC0dHRysjIkCS9++67WrZsmaZMmaIyZcrk+FyBAmcBwJ8kJiZakqyWLVvmqP+OHTssSVZMTIxD+4ABAyxJ1qpVq+xtwcHBliRr7dq19rZTp05Zbm5u1ksvvWRvO3z4sCXJeuONNxzGjI6OtoKDg7PUMHz4cOvPP84mTJhgSbJOnz593bqvzjFjxgx7W82aNa2SJUtaZ86csbft3LnTcnJysjp37pxlvmeeecZhzNatW1vFihW77px/Pg8vLy/LsizrySeftBo2bGhZlmVlZGRYgYGB1ogRI7J9DVJTU62MjIws5+Hm5maNHDnS3rZly5Ys53ZVZGSkJcmaNm1atvsiIyMd2r755htLkjV69Gjr0KFDlre3t9WqVau/PEegsOEKDwAHSUlJkiQfH58c9V+6dKkk6cUXX3Rof+mllyQpy1qf8PBw1a1b175dokQJhYWF6dChQ3+75mtdXfvzxRdfKDMzM0fHHD9+XDt27FCXLl1UtGhRe/tdd92lxo0b28/zz3r27OmwXbduXZ05c8b+GuZEx44dtXr1ap04cUKrVq3SiRMnsr2dJV1Z9+PkdOXHdkZGhs6cOWO/Xbd9+/Ycz+nm5qauXbvmqO8jjzyiZ599ViNHjlSbNm3k7u6ud999N8dzAYUFgQeAA19fX0nS+fPnc9T/l19+kZOTk0JDQx3aAwMD5e/vr19++cWhvXz58lnGCAgI0Llz5/5mxVm1b99ederUUUxMjEqVKqUOHTro008/vWH4uVpnWFhYln1Vq1bVH3/8oQsXLji0X3suAQEBkpSrc2nWrJl8fHw0b948xcXF6b777svyWl6VmZmpCRMmqHLlynJzc1Px4sVVokQJ7dq1S4mJiTmes2zZsrlaoPzmm2+qaNGi2rFjhyZPnqySJUvm+FigsCDwAHDg6+urMmXK6Mcff8zVcdcuGr4eZ2fnbNsty/rbc1xdX3KVh4eH1q5dqxUrVujpp5/Wrl271L59ezVu3DhL35txM+dylZubm9q0aaNZs2Zp4cKF1726I0mvvfaaXnzxRdWrV08fffSRvvnmGy1fvlzVqlXL8ZUs6crrkxs//PCDTp06JUnavXt3ro4FCgsCD4AsWrRoofj4eG3atOkv+wYHByszM1MHDhxwaD958qQSEhLsT1zlhYCAAIcnmq669iqSJDk5Oalhw4Z66623tGfPHo0ZM0arVq3St99+m+3YV+vct29fln0///yzihcvLi8vr5s7gevo2LGjfvjhB50/fz7bhd5Xff7552rQoIE++OADdejQQY888ogaNWqU5TXJafjMiQsXLqhr164KDw9Xjx49NG7cOG3ZsiXPxgduFQIPgCxefvlleXl5KSYmRidPnsyyPz4+XpMmTZJ05ZaMpCxPUr311luSpObNm+dZXZUqVVJiYqJ27dplbzt+/LgWLlzo0O/s2bNZjr36BnzXPip/VenSpVWzZk3NmjXLIUD8+OOPWrZsmf0880ODBg00atQovf322woMDLxuP2dn5yxXjz777DP9/vvvDm1Xg1l24TC3Bg0apKNHj2rWrFl66623FBISoujo6Ou+jkBhxRsPAsiiUqVKmjt3rtq3b6+qVas6vNPyxo0b9dlnn6lLly6SpBo1aig6OlrvvfeeEhISFBkZqe+//16zZs1Sq1atrvvI89/RoUMHDRo0SK1bt1afPn2UkpKiqVOnqkqVKg6LdkeOHKm1a9eqefPmCg4O1qlTp/TOO++oXLlyeuihh647/htvvKFHH31UERER6tatmy5evKgpU6bIz89PsbGxeXYe13JyctK//vWvv+zXokULjRw5Ul27dlXt2rW1e/duxcXFqWLFig79KlWqJH9/f02bNk0+Pj7y8vLSAw88oAoVKuSqrlWrVumdd97R8OHD7Y/Jz5gxQ/Xr19fQoUM1bty4XI0HFKgCfkoMQCG2f/9+q3v37lZISIjl6upq+fj4WHXq1LGmTJlipaam2vulp6dbI0aMsCpUqGAVKVLECgoKsoYMGeLQx7KuPJbevHnzLPNc+zj09R5LtyzLWrZsmXXnnXdarq6uVlhYmPXRRx9leSx95cqVVsuWLa0yZcpYrq6uVpkyZaynnnrK2r9/f5Y5rn10e8WKFVadOnUsDw8Py9fX13rsscesPXv2OPS5Ot+1j73PmDHDkmQdPnz4uq+pZTk+ln4913ss/aWXXrJKly5teXh4WHXq1LE2bdqU7ePkX3zxhRUeHm65uLg4nGdkZKRVrVq1bOf88zhJSUlWcHCwVatWLSs9Pd2hX//+/S0nJydr06ZNNzwHoDCxWVYuVtcBAADchljDAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPN54sBDJzMzUsWPH5OPjk6dvDQ8AgIksy9L58+dVpkwZOTnd+BoOgacQOXbsmIKCggq6DAAAbiu//vqrypUrd8M+BJ5CxMfHR5IU1neunN08C7gaAH/27aC8+4gMAHnjfFKSQisE2X9/3giBpxC5ehvL2c1Tzm7586nMAP4eX1/fgi4BwHXkZBkIi5YBAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDyXgi6gsIqNjdWiRYu0Y8eOgi4FBaR7ZEV1j6zo0Hbkjwtq986mLH0ndqyp2qHFNXDeTq3Zd9refl+FAD1bv5IqlfRWanqGluw8rqmr4pVhWfY+jcJLqstDFVS+mKfOXbikz7b8po82/ZJ/JwYYYMP2g5oyZ4V2/nxUJ/5I0kdvdFfz+jUc+uw7fEKxUxZpw/aDysjIVFiFQM0aF6OgwKKSpJkL1uvzb7Zq177fdP5Cqo6sGic/H89s50u7lK5GXd7Ujwd+19qPBqt6WLl8P0fkLQKPJJvNpoULF6pVq1b2tgEDBqh3794FVxQKhfhTyeo1Z7t9+3KmlaXPUw+Ul5W1WZVLeWvCU3drxvrDil30k0r4umlws6pycrJp8vIDkqSI0GIa2fpOvfnfffou/qwqlPDUKy3ClXY5Q59t+S3fzgu43aVcTNOdVcqq0+MRevrl6Vn2H/7ttB7t/pY6PV5bQ55tLh8vd+2NPy531yL2PhdT09UwIlwNI8I18j9f3nC+4ZO/UGAJP/144Pc8PxfcGgSe6/D29pa3t3dBl4EClpFp6cyFS9fdX7mUtzpGlFeX6d/r65fqOexrVK2UDp48rw/WHpYk/XbuoqasPKDXnqiu99ccUsqlDDWrXlpr9p3Wgm1XfogeS7ioWeuPqHPtEAIPcAON61RT4zrVrrt/1DuL1bh2NY3s08reVqFcCYc+z3VsIElav23/DedavuEnfbt5r2a9HqMVG/f8/aJRoAp0DU/9+vXVp08fvfzyyypatKgCAwMVGxtr35+QkKCYmBiVKFFCvr6+evjhh7Vz506HMUaPHq2SJUvKx8dHMTExGjx4sGrWrGnfv2XLFjVu3FjFixeXn5+fIiMjtX37//5iDwkJkSS1bt1aNpvNvh0bG2sfZ9myZXJ3d1dCQoLD3H379tXDDz9s316/fr3q1q0rDw8PBQUFqU+fPrpw4cJNv04oOEFFPbWkf10t7F1bI1tXUylfN/s+NxcnjWpzp95Yui/bUOTq7KRLGZkObWnpmXIv4qw7SvtKkoq4OCnt8jV9LmeolJ+7Svu558MZAebLzMzU8g0/KbR8ST3R+21VfmSwGnV5Q0tW7/zrg69x6kyS+r32saaN6CxPd9d8qBa3SoEvWp41a5a8vLy0efNmjRs3TiNHjtTy5cslSW3bttWpU6f09ddfa9u2bapVq5YaNmyos2fPSpLi4uI0ZswYvf7669q2bZvKly+vqVOnOox//vx5RUdHa/369fruu+9UuXJlNWvWTOfPn5d0JRBJ0owZM3T8+HH79p81bNhQ/v7+mj9/vr0tIyND8+bNU1RUlCQpPj5eTZs21RNPPKFdu3Zp3rx5Wr9+vXr16nXdc09LS1NSUpLDFwqPH39P1MgvflLfuB/0+tKfVcbfQ+91uVeers6SpP5Nqmj3r4lau/90tsd/F39G1cv565FqpeRkk0r4uCmmXgVJUnFvV3ufBneU1H0VAmSTVL6opzo+GHylj49btuMCuLHTZ5OVnJKmibOWq2FEuBZM6aXm9Wvo6Zff14ZtB3I8jmVZen7ER+ra5iHdHR6cjxXjVijwW1p33XWXhg8fLkmqXLmy3n77ba1cuVIeHh76/vvvderUKbm5XfnB/+abb2rRokX6/PPP1aNHD02ZMkXdunVT165dJUnDhg3TsmXLlJycbB//z1dgJOm9996Tv7+/1qxZoxYtWqhEiSuXOP39/RUYGJhtjc7OzurQoYPmzp2rbt26SZJWrlyphIQEPfHEE5KksWPHKioqSv369bOfy+TJkxUZGampU6fK3T3rX+tjx47ViBEj/u5Lh3y26eAZ+78PnpJ+/C1JX/Z9SI3CS+lcyiXdG1JUT7+3+brHbz50VlNWHNDg5lUV27qa0i9b+mDdId0dHKCrS4EWbf9d5QI8NL5DTbk423QhLUPzNh9Vj/qVlJndwiAAfynTunLV9NHI6nq+45XfAdXDyun7XYf04YL1qnNP5RyN8968NUpOSVX/Lo/kW624dQpF4Pmz0qVL69SpU9q5c6eSk5NVrFgxh/0XL15UfHy8JGnfvn16/vnnHfbff//9WrVqlX375MmT+te//qXVq1fr1KlTysjIUEpKio4ePZqrOqOiovTggw/q2LFjKlOmjOLi4tS8eXP5+/tLknbu3Kldu3YpLi7OfoxlWcrMzNThw4dVtWrVLGMOGTJEL774on07KSlJQUFBuaoLt05y2mUdPXNB5Yp6qFJJb5Ur6qGVgyId+vy77V3acTRBz83eJkma+91Rzf3uqIp7u+p86mWV9ndXr4aV9XvCRfsxb688qHdWHVQxbzedu3BJ91W88gTJ7+cuCkDuFfP3louzk+6oUNqhvUqFQH2341COx1m7db+27D6sUnX6ObQ3iB6ntk3v1dTYznlRLm6RAg88RYoUcdi22WzKzMxUcnKySpcurdWrV2c55mrIyIno6GidOXNGkyZNUnBwsNzc3BQREaFLl66/EDU79913nypVqqRPPvlEzz33nBYuXKiZM2fa9ycnJ+vZZ59Vnz59shxbvnz5bMd0c3OzX71C4edRxFlli3rqj90ntPKnk/riB8enNT55LkITlu3X+mxucf2RfOX/2yN3BupEYqr2HXe8fZlpSafPp0mSmlQL1K5fE5SQkp5PZwKYzbWIi+4OD9aBX046tMcfPaWg0gE5HuffA57Uqz1b2LdP/JGoJ3r/Rx++1lX3VAvJq3JxixR44LmeWrVq6cSJE3JxcbEvJL5WWFiYtmzZos6d/5eyr12Ds2HDBr3zzjtq1qyZJOnXX3/VH3/84dCnSJEiysjI+MuaoqKiFBcXp3LlysnJyUnNmzd3qHfPnj0KDQ3N6SmikOvTuLLW7T+tEwmpKu7jph71Kyoz09KyH08oISU924XKJxNTdSwh1b7dKSJYm+L/kGVJ9e8oqeg6IXrl8932W1p+HkXUMLykth05J1cXJz1Ws4weDi+pnrO23arTBG5LySlpOvzr//64+OXYGe3e95v8/TwVFFhUfZ5upGde+VC17w5V3XuraMWmPfrvuh+1eFpf+zEn/0jSqTNJOvTrld8JPx08Jh9Pd5ULDFCAn5f9/Xqu8va88gdqhbIlVLZUzoMTCodCG3gaNWqkiIgItWrVSuPGjVOVKlV07NgxLVmyRK1bt9a9996r3r17q3v37rr33ntVu3ZtzZs3T7t27VLFiv97s7jKlStrzpw5uvfee5WUlKSBAwfKw8PDYa6QkBCtXLlSderUkZubmwICsv+PHBUVpdjYWI0ZM0ZPPvmkw9WZQYMG6cEHH1SvXr0UExMjLy8v7dmzR8uXL9fbb7+dPy8S8lVJHzeNblNdfh5FdC7lknYeTdAzH27J1ZWX2qHF1LVuiIo4O+nAyWQNmLfTYW2QJDWvUVp9GleWTTbt/u3K7bA9x1jADtzIjr2/6LGek+3br05YIEl6qvkDeif2abVoUENvDemgCTOXafD4zxVavqRmvx6jiJqV7MfMWLBOr0//2r7dvMdESdJ/hnVSx8cevDUnglum0AYem82mpUuX6tVXX1XXrl11+vRpBQYGql69eipVqpSkKwHk0KFDGjBggFJTU9WuXTt16dJF33//vX2cDz74QD169FCtWrUUFBSk1157TQMGDHCYa/z48XrxxRc1ffp0lS1bVkeOHMm2ptDQUN1///36/vvvNXHiRId9d911l9asWaNXX31VdevWlWVZqlSpktq3b5+nrwtunX8t+DFX/e8fuSJL2/N/etPC7CReTFe3D7fmah4A0kP3VNG5LTf+Y7LT4xHq9HjEdfcP7tFcg3s0v+7+a5UvU+wv50ThZbMssx4Fady4sQIDAzVnzpyCLiXXkpKS5Ofnp/CXF8nZzaugywHwJ98Pa1TQJQC4RlJSkkoV81NiYqJ8fX1v2LfQXuHJiZSUFE2bNk1NmjSRs7OzPv74Y61YscL+Pj4AAADSbR54rt72GjNmjFJTUxUWFqb58+erUSP+EgMAAP9zWwceDw8PrViRdd0EAADAnxX4R0sAAADkNwIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwnktOOn355Zc5HvDxxx//28UAAADkhxwFnlatWuVoMJvNpoyMjJupBwAAIM/lKPBkZmbmdx0AAAD55qbW8KSmpuZVHQAAAPkm14EnIyNDo0aNUtmyZeXt7a1Dhw5JkoYOHaoPPvggzwsEAAC4WbkOPGPGjNHMmTM1btw4ubq62tvvvPNOvf/++3laHAAAQF7IdeCZPXu23nvvPUVFRcnZ2dneXqNGDf388895WhwAAEBeyHXg+f333xUaGpqlPTMzU+np6XlSFAAAQF7KdeAJDw/XunXrsrR//vnnuvvuu/OkKAAAgLyUo8fS/2zYsGGKjo7W77//rszMTC1YsED79u3T7Nmz9dVXX+VHjQAAADcl11d4WrZsqcWLF2vFihXy8vLSsGHDtHfvXi1evFiNGzfOjxoBAABuSq6v8EhS3bp1tXz58ryuBQAAIF/8rcAjSVu3btXevXslXVnXc8899+RZUQAAAHkp14Hnt99+01NPPaUNGzbI399fkpSQkKDatWvrk08+Ubly5fK6RgAAgJuS6zU8MTExSk9P1969e3X27FmdPXtWe/fuVWZmpmJiYvKjRgAAgJuS6ys8a9as0caNGxUWFmZvCwsL05QpU1S3bt08LQ4AACAv5PoKT1BQULZvMJiRkaEyZcrkSVEAAAB5KdeB54033lDv3r21detWe9vWrVvVt29fvfnmm3laHAAAQF7I0S2tgIAA2Ww2+/aFCxf0wAMPyMXlyuGXL1+Wi4uLnnnmGbVq1SpfCgUAAPi7chR4Jk6cmM9lAAAA5J8cBZ7o6Oj8rgMAACDf/O03HpSk1NRUXbp0yaHN19f3pgoCAADIa7letHzhwgX16tVLJUuWlJeXlwICAhy+AAAACptcB56XX35Zq1at0tSpU+Xm5qb3339fI0aMUJkyZTR79uz8qBEAAOCm5PqW1uLFizV79mzVr19fXbt2Vd26dRUaGqrg4GDFxcUpKioqP+oEAAD423J9hefs2bOqWLGipCvrdc6ePStJeuihh7R27dq8rQ4AACAP5DrwVKxYUYcPH5Yk3XHHHfr0008lXbnyc/XDRAEAAAqTXAeerl27aufOnZKkwYMH6z//+Y/c3d3Vv39/DRw4MM8LBAAAuFm5XsPTv39/+78bNWqkn3/+Wdu2bVNoaKjuuuuuPC0OAAAgL9zU+/BIUnBwsIKDg/OiFgAAgHyRo8AzefLkHA/Yp0+fv10MAABAfrBZlmX9VacKFSrkbDCbTYcOHbrpov6pkpKS5Ofnp52HTsrHh3esBgqT8MYDCroEANewMi4pbfd0JSYm/uUnPeToCs/Vp7IAAABuR7l+SgsAAOB2Q+ABAADGI/AAAADjEXgAAIDxCDwAAMB4fyvwrFu3Tp06dVJERIR+//13SdKcOXO0fv36PC0OAAAgL+Q68MyfP19NmjSRh4eHfvjhB6WlpUmSEhMT9dprr+V5gQAAADcr14Fn9OjRmjZtmqZPn64iRYrY2+vUqaPt27fnaXEAAAB5IdeBZ9++fapXr16Wdj8/PyUkJORFTQAAAHkq14EnMDBQBw8ezNK+fv16VaxYMU+KAgAAyEu5Djzdu3dX3759tXnzZtlsNh07dkxxcXEaMGCAnnvuufyoEQAA4Kbk6LO0/mzw4MHKzMxUw4YNlZKSonr16snNzU0DBgxQ796986NGAACAm5LrwGOz2fTqq69q4MCBOnjwoJKTkxUeHi5vb+/8qA8AAOCm5TrwXOXq6qrw8PC8rAUAACBf5DrwNGjQQDab7br7V61adVMFAQAA5LVcB56aNWs6bKenp2vHjh368ccfFR0dnVd1AQAA5JlcB54JEyZk2x4bG6vk5OSbLggAACCv5dmHh3bq1EkffvhhXg0HAACQZ/Is8GzatEnu7u55NRwAAECeyfUtrTZt2jhsW5al48ePa+vWrRo6dGieFQYAAJBXch14/Pz8HLadnJwUFhamkSNH6pFHHsmzwgAAAPJKrgJPRkaGunbtqurVqysgICC/agIAAMhTuVrD4+zsrEceeYRPRQcAALeVXC9avvPOO3Xo0KH8qAUAACBf5DrwjB49WgMGDNBXX32l48ePKykpyeELAACgsMnxGp6RI0fqpZdeUrNmzSRJjz/+uMNHTFiWJZvNpoyMjLyvEgAA4CbkOPCMGDFCPXv21Lfffpuf9QAAAOS5HAcey7IkSZGRkflWDAAAQH7I1RqeG31KOgAAQGGVq/fhqVKlyl+GnrNnz95UQQAAAHktV4FnxIgRWd5pGQAAoLDLVeDp0KGDSpYsmV+1AAAA5Iscr+Fh/Q4AALhd5TjwXH1KCwAA4HaT41tamZmZ+VkHAABAvsn1R0sAAADcbgg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeC4FXcCttnr1ajVo0EDnzp2Tv7//dfuFhISoX79+6tev3y2rDYXLex+v1Ir1u3Xo19Nyd3NRzfAQvRTTXBWCSkqSEpJS9Pbsb7Rx234dP3VOAX7ealjnTvXp0kQ+Xh72cXbvO6q33l+qPQd+k81mU/WwIL3UvYXuqFRGkvT7ibNq/PRrWeb/eFJv1QgPvjUnC9xGdn4xQuXLFMvS/v5nazVw3KeKbl1HTza5V3eFlZOvt4eCGwxUUvLFbMdyLeKiFTMHqHqVcqobNVY/7v/dvq9aaBm98XI73R0erDMJyXpv3hpNnrMi384L+esfF3hq166t48ePy8/PT5I0c+ZM9evXTwkJCQ79tmzZIi8vrwKoEIXF1l2H9NTjdXRnWJAyMjI18cOlihn8nha/P1CeHm46fSZRp88kaWCPFqoUXErHTp7TiEnzdfpMoiYOi5YkXbiYph5D3leDiHAN69NGlzMy9Z/Z36j7kOlaNfdfKuLibJ/vg9efVWhIKfu2vy///4DsPBz9hpydbfbtqpXKaNF/emvRih8kSR7uRbRy0x6t3LRHw3u1vOFYI/q01InTiapepZxDu4+Xu+a/3Utrvv9ZL/77E4VXKqspw6KUmHxRsxZuyPuTQr77xwUeV1dXBQYG/mW/EiVK3IJqUJi9N7a7w/ZrAzvoobax2nPgN917VyVVrlBak4ZH2/eXL1Ncfbs+qkGvz9XljAy5ODvr8NFTSjyfot7RTVW6pL8k6fmnH1GrHuN17OQ5BZctbj/e39dTJYr63pJzA25nZxKSHbb7Rd+pQ7+e1obtByRJ0z5eLUmqU6vyDcdpVDtcDR6oquhB76txnWoO+9o2vVeuLs7qNTJO6Zcz9POhE6oeVlbPd2xA4LlNFco1PPXr11evXr3Uq1cv+fn5qXjx4ho6dKgsy5IknTt3Tp07d1ZAQIA8PT316KOP6sCBA/bjf/nlFz322GMKCAiQl5eXqlWrpqVLl0q6ckvLZrMpISFBq1evVteuXZWYmCibzSabzabY2FhJV25pTZw4UZLUsWNHtW/f3qHG9PR0FS9eXLNnz5YkZWZmauzYsapQoYI8PDxUo0YNff755/n8SuFWOn8hVZLk5+N53T7JF1Ll7ekuF+crV24qBJWQv6+n5v93sy6lX1ZqWrrmf/29KpYvqbKBAQ7HvjBshh5qO1yd+r2tVRt/yr8TAQxSxMVZ7R69T3FfbsrVcSWK+mjiK0+p5/DZSkm9lGX/fdUraOMPB5V+OcPetnLTXlUJCZSfj0eW/ij8Cu0VnlmzZqlbt276/vvvtXXrVvXo0UPly5dX9+7d1aVLFx04cEBffvmlfH19NWjQIDVr1kx79uxRkSJF9MILL+jSpUtau3atvLy8tGfPHnl7e2eZo3bt2po4caKGDRumffv2SVK2/aKiotS2bVslJyfb93/zzTdKSUlR69atJUljx47VRx99pGnTpqly5cpau3atOnXqpBIlSigyMjLbc0xLS1NaWpp9Oykp6aZfN+SPzMxM/XvqF6pVLUSVK5TOts+5xAuaGrdcbZs9aG/z8nTXrDefU6/YmZoWd+Xef3DZ4npvbHd7KPL0cNPLzz6mu6uFyMnJpuXrdqt37ExNie2ih2tXy3YuAFc0r3+X/Lw9NPerzbk67p3hnTRjwXrt2HtUQaWLZtlfspivjh4749B2+ux5SVKpYr5KPJ/9miAUXoU28AQFBWnChAmy2WwKCwvT7t27NWHCBNWvX19ffvmlNmzYoNq1a0uS4uLiFBQUpEWLFqlt27Y6evSonnjiCVWvXl2SVLFixWzncHV1lZ+fn2w22w1vczVp0kReXl5auHChnn76aUnS3Llz9fjjj8vHx0dpaWl67bXXtGLFCkVERNjnXL9+vd59993rBp6xY8dqxIgRf/s1wq0zaspCHThyQh9NeCHb/ckXUtXzX++rUnApvdD5EXt7alq6/vXWp6pVLURvvhKlzAxLMz5fref+9YE+fbuf3N2KKMDPS12e/N//keph5XXqTJI+/Gw1gQf4C50er60Vm/boxB+JOT6mR/tIeXu6a8LMZflYGQqbQnlLS5IefPBB2Wz/W5QWERGhAwcOaM+ePXJxcdEDDzxg31esWDGFhYVp7969kqQ+ffpo9OjRqlOnjoYPH65du3bdVC0uLi5q166d4uLiJEkXLlzQF198oaioKEnSwYMHlZKSosaNG8vb29v+NXv2bMXHx1933CFDhigxMdH+9euvv95Uncgfo6cs0JrNezTzjZ4KLOGfZf+FlFT1eGW6vDzcNSW2i8NC5CWrtuvYiXMaM6C9qoeVV43wYI0bEqXfT5zVqo0/XnfOu+4or6PH/siP0wGMERQYoPr3h2n2oo25Oq7evVV0X/UKOrlhok5vmqTtC4ZLkr6d9bLeGX7lj9pTZ5JUoqiPw3FXt0+e4Wr87ajQXuG5GTExMWrSpImWLFmiZcuWaezYsRo/frx69+79t8eMiopSZGSkTp06peXLl8vDw0NNmzaVJCUnX1lAt2TJEpUtW9bhODc3t+uO6ebmdsP9KFiWZWnM2wu1YsOPmvnmcypXOutjsMkXUtV9yHS5FnHWf0Z2lZtrEYf9F9PSZXOyOYR3JyebJJsy/39NWnZ+jj/GAmbgL3R8LEKnz53Xsg25W/M2+M3PNWbaV/btwOJ+WvB2Lz3zygxt++mIJGnL7sP613OPycXZSZczMiVJDR64Q/uPnOB21m2q0F7h2bzZ8X7sd999p8qVKys8PFyXL1922H/mzBnt27dP4eHh9ragoCD17NlTCxYs0EsvvaTp06dnO4+rq6syMjKy3fdntWvXVlBQkObNm6e4uDi1bdtWRYpc+eUWHh4uNzc3HT16VKGhoQ5fQUFBf+f0UQiMmrJAi1du1xtDouTl6abTZ5N0+mySUtPSJV0JOzGD39PF1Esa9VI7Jaek2vtk/P8PyNq1qijp/EWNmrJA8b+c1IEjJ/TqG/Pk4uykB2qESpIWLduiJat+0KGjp3To6Cm9O3elFnzzvaJa1imwcwcKO5vNpqjHHtQnSzbbv9+uKlnMR3dWKauKQVeegqwWWkZ3Vikrf98rDxz8dvKc9sYft38dPHpKknT499M6dipBkvT5f7fq0uUMTRkapTsqBqp141p6tkN9vTP321t3kshThfYKz9GjR/Xiiy/q2Wef1fbt2zVlyhSNHz9elStXVsuWLdW9e3e9++678vHx0eDBg1W2bFm1bHnl/Rb69eunRx99VFWqVNG5c+f07bffqmrVqtnOExISouTkZK1cuVI1atSQp6enPD2zfwqnY8eOmjZtmvbv369vv/3ff3ofHx8NGDBA/fv3V2Zmph566CElJiZqw4YN8vX1VXR0dLbjoXD7ZPGVpz6iB0x1aB8zoL1aN7lPew7+pl0/H5UkNY3+t0Of5XNeUdnAoqpYvqTeGfWM3pmzTB37TpHNyaaqlcrqvde6q0Sx/13BmRq3XMdPnZOzk7MqlC+h8a92UpN6NfL5DIHbV/37wxRUuqg++vK7LPu6tqmrwT2a2beXTu8vSXp+xBx9nMPFzUkXUvVEr7f1xsvt9O3sQTqTkKw33v+aR9JvYzbLusF19QJSv359VatWTZmZmZo7d66cnZ313HPPafTo0bLZbDp37pz69u2rL7/8UpcuXVK9evU0ZcoUVa585T0Xevfura+//lq//fabfH191bRpU02YMEHFihXL9p2Wn3vuOX322Wc6c+aMhg8frtjY2GzfaXnv3r0KDw9XcHCwDh8+7HCbwrIsTZ48WVOnTtWhQ4fk7++vWrVq6ZVXXlG9evVydN5JSUny8/PTzkMn5ePD7QygMAlvPKCgSwBwDSvjktJ2T1diYqJ8fW/8e7PQBp6aNWva3wfnn4LAAxReBB6g8MlN4Cm0a3gAAADyCoEHAAAYr1AuWl69enVBlwAAAAzCFR4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAYj8ADAACMR+ABAADGI/AAAADjEXgAAIDxCDwAAMB4BB4AAGA8Ag8AADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAAgPEIPAAAwHgEHgAAYDyXgi4A/2NZliQp+fz5Aq4EwLWsjEsFXQKAa1z9vrz6+/NGCDyFyPn/Dzp1aoQWcCUAANw+zp8/Lz8/vxv2sVk5iUW4JTIzM3Xs2DH5+PjIZrMVdDm4SUlJSQoKCtKvv/4qX1/fgi4HwP/je9MclmXp/PnzKlOmjJycbrxKhys8hYiTk5PKlStX0GUgj/n6+vJDFSiE+N40w19d2bmKRcsAAMB4BB4AAGA8Ag+QT9zc3DR8+HC5ubkVdCkA/oTvzX8mFi0DAADjcYUHAAAYj8ADAACMR+ABAADGI/AABSw2NlY1a9Ys6DIA461evVo2m00JCQk37BcSEqKJEyfekppw67BoGbiFbDabFi5cqFatWtnbkpOTlZaWpmLFihVcYcA/wKVLl3T27FmVKlVKNptNM2fOVL9+/bIEoNOnT8vLy0uenp4FUyjyBe+0DBQwb29veXt7F3QZgPFcXV0VGBj4l/1KlChxC6rBrcYtLfwj1K9fX3369NHLL7+sokWLKjAwULGxsfb9CQkJiomJUYkSJeTr66uHH35YO3fudBhj9OjRKlmypHx8fBQTE6PBgwc73IrasmWLGjdurOLFi8vPz0+RkZHavn27fX9ISIgkqXXr1rLZbPbtP9/SWrZsmdzd3bP8xdm3b189/PDD9u3169erbt268vDwUFBQkPr06aMLFy7c9OsEFLT69eurV69e6tWrl/z8/FS8eHENHTrU/mnY586dU+fOnRUQECBPT089+uijOnDggP34X375RY899pgCAgLk5eWlatWqaenSpZIcb2mtXr1aXbt2VWJiomw2m2w2m/1nwp9vaXXs2FHt27d3qDE9PV3FixfX7NmzJV35HMSxY8eqQoUK8vDwUI0aNfT555/n8yuF3CLw4B9j1qxZ8vLy0ubNmzVu3DiNHDlSy5cvlyS1bdtWp06d0tdff61t27apVq1aatiwoc6ePStJiouL05gxY/T6669r27ZtKl++vKZOneow/vnz5xUdHa3169fru+++U+XKldWsWTOdP39e0pVAJEkzZszQ8ePH7dt/1rBhQ/n7+2v+/Pn2toyMDM2bN09RUVGSpPj4eDVt2lRPPPGEdu3apXnz5mn9+vXq1atX3r9oQAGYNWuWXFxc9P3332vSpEl666239P7770uSunTpoq1bt+rLL7/Upk2bZFmWmjVrpvT0dEnSCy+8oLS0NK1du1a7d+/W66+/nu0V1Nq1a2vixIny9fXV8ePHdfz4cQ0YMCBLv6ioKC1evFjJycn2tm+++UYpKSlq3bq1JGns2LGaPXu2pk2bpp9++kn9+/dXp06dtGbNmvx4efB3WcA/QGRkpPXQQw85tN13333WoEGDrHXr1lm+vr5Wamqqw/5KlSpZ7777rmVZlvXAAw9YL7zwgsP+OnXqWDVq1LjunBkZGZaPj4+1ePFie5ska+HChQ79hg8f7jBO3759rYcffti+/c0331hubm7WuXPnLMuyrG7dulk9evRwGGPdunWWk5OTdfHixevWA9wOIiMjrapVq1qZmZn2tkGDBllVq1a19u/fb0myNmzYYN/3xx9/WB4eHtann35qWZZlVa9e3YqNjc127G+//daSZP9emjFjhuXn55elX3BwsDVhwgTLsiwrPT3dKl68uDV79mz7/qeeespq3769ZVmWlZqaanl6elobN250GKNbt27WU089levzR/7hCg/+Me666y6H7dKlS+vUqVPauXOnkpOTVaxYMft6Gm9vbx0+fFjx8fGSpH379un+++93OP7a7ZMnT6p79+6qXLmy/Pz85Ovrq+TkZB09ejRXdUZFRWn16tU6duyYpCtXl5o3by5/f39J0s6dOzVz5kyHWps0aaLMzEwdPnw4V3MBhdGDDz4om81m346IiNCBAwe0Z88eubi46IEHHrDvK1asmMLCwrR3715JUp8+fTR69GjVqVNHw4cP165du26qFhcXF7Vr105xcXGSpAsXLuiLL76wX3E9ePCgUlJS1LhxY4fvydmzZ9t/fqBwYNEy/jGKFCnisG2z2ZSZmank5GSVLl1aq1evznLM1ZCRE9HR0Tpz5owmTZqk4OBgubm5KSIiQpcuXcpVnffdd58qVaqkTz75RM8995wWLlyomTNn2vcnJyfr2WefVZ8+fbIcW758+VzNBZgmJiZGTZo00ZIlS7Rs2TKNHTtW48ePV+/evf/2mFFRUYqMjNSpU6e0fPlyeXh4qGnTppJkv9W1ZMkSlS1b1uE4PqurcCHw4B+vVq1aOnHihFxcXOwLia8VFhamLVu2qHPnzva2a9fgbNiwQe+8846aNWsmSfr111/1xx9/OPQpUqSIMjIy/rKmqKgoxcXFqVy5cnJyclLz5s0d6t2zZ49CQ0NzeorAbWXz5s0O21fXxIWHh+vy5cvavHmzateuLUk6c+aM9u3bp/DwcHv/oKAg9ezZUz179tSQIUM0ffr0bAOPq6trjr4fa9euraCgIM2bN09ff/212rZta/8DKjw8XG5ubjp69KgiIyNv5rSRz7ilhX+8Ro0aKSIiQq1atdKyZct05MgRbdy4Ua+++qq2bt0qSerdu7c++OADzZo1SwcOHNDo0aO1a9cuh8vulStX1pw5c7R3715t3rxZUVFR8vDwcJgrJCREK1eu1IkTJ3Tu3Lnr1hQVFaXt27drzJgxevLJJx3+Uhw0aJA2btyoXr16aceOHTpw4IC++OILFi3DGEePHtWLL76offv26eOPP9aUKVPUt29fVa5cWS1btlT37t21fv167dy5U506dVLZsmXVsmVLSVK/fv30zTff6PDhw9q+fbu+/fZbVa1aNdt5QkJClJycrJUrV+qPP/5QSkrKdWvq2LGjpk2bpuXLl9tvZ0mSj4+PBgwYoP79+2vWrFmKj4/X9u3bNWXKFM2aNStvXxjcFAIP/vFsNpuWLl2qevXqqWvXrqpSpYo6dOigX375RaVKlZJ0JYAMGTJEAwYMUK1atXT48GF16dJF7u7u9nE++OADnTt3TrVq1dLTTz+tPn36qGTJkg5zjR8/XsuXL1dQUJDuvvvu69YUGhqq+++/X7t27XL44SpdWYu0Zs0a7d+/X3Xr1tXdd9+tYcOGqUyZMnn4qgAFp3Pnzrp48aLuv/9+vfDCC+rbt6969Ogh6cpTjvfcc49atGihiIgIWZalpUuX2q+4ZGRk6IUXXlDVqlXVtGlTValSRe+8806289SuXVs9e/ZU+/btVaJECY0bN+66NUVFRWnPnj0qW7as6tSp47Bv1KhRGjp0qMaOHWufd8mSJapQoUIevSLIC7zTMvA3NW7cWIGBgZozZ05BlwIYo379+qpZsyYf7YA8xxoeIAdSUlI0bdo0NWnSRM7Ozvr444+1YsUK+/v4AAAKNwIPkANXb3uNGTNGqampCgsL0/z589WoUaOCLg0AkAPc0gIAAMZj0TIAADAegQcAABiPwAMAAIxH4AEAAMYj8AAAAOMReAAYoUuXLmrVqpV9u379+urXr98tr2P16tWy2WxKSEi4bh+bzaZFixbleMzY2FjVrFnzpuo6cuSIbDabduzYcVPjALcrAg+AfNOlSxfZbDbZbDa5uroqNDRUI0eO1OXLl/N97gULFmjUqFE56puTkALg9sYbDwLIV02bNtWMGTOUlpampUuX6oUXXlCRIkU0ZMiQLH0vXbokV1fXPJm3aNGieTIOADNwhQdAvnJzc1NgYKCCg4P13HPPqVGjRvryyy8l/e821JgxY1SmTBmFhYVJkn799Ve1a9dO/v7+Klq0qFq2bKkjR47Yx8zIyNCLL74of39/FStWTC+//LKufQ/Va29ppaWladCgQQoKCpKbm5tCQ0P1wQcf6MiRI2rQoIEkKSAgQDabTV26dJEkZWZmauzYsapQoYI8PDxUo0YNff755w7zLF26VFWqVJGHh4caNGjgUGdODRo0SFWqVJGnp6cqVqyooUOHKj09PUu/d999V0FBQfL09FS7du2UmJjosP/9999X1apV5e7urjvuuOO6H5oJ/BMReADcUh4eHrp06ZJ9e+XKldq3b5+WL1+ur776Sunp6WrSpIl8fHy0bt06bdiwQd7e3mratKn9uPHjx2vmzJn68MMPtX79ep09e1YLFy684bydO3fWxx9/rMmTJ2vv3r1699135e3traCgIM2fP1+StG/fPh0/flyTJk2SJI0dO1azZ8/WtGnT9NNPP6l///7q1KmT1qxZI+lKMGvTpo0ee+wx7dixQzExMRo8eHCuXxMfHx/NnDlTe/bs0aRJkzR9+nRNmDDBoc/Bgwf16aefavHixfrvf/+rH374Qc8//7x9f1xcnIYNG6YxY8Zo7969eu211zR06FDNmjUr1/UARrIAIJ9ER0dbLVu2tCzLsjIzM63ly5dbbm5u1oABA+z7S5UqZaWlpdmPmTNnjhUWFmZlZmba29LS0iwPDw/rm2++sSzLskqXLm2NGzfOvj89Pd0qV66cfS7LsqzIyEirb9++lmVZ1r59+yxJ1vLly7Ot89tvv7UkWefOnbO3paamWp6entbGjRsd+nbr1s166qmnLMuyrCFDhljh4eEO+wcNGpRlrGtJshYuXHjd/W+88YZ1zz332LeHDx9uOTs7W7/99pu97euvv7acnJys48ePW5ZlWZUqVbLmzp3rMM6oUaOsiIgIy7Is6/Dhw5Yk64cffrjuvIDJWMMDIF999dVX8vb2Vnp6ujIzM9WxY0fFxsba91evXt1h3c7OnTt18OBB+fj4OIyTmpqq+Ph4JSYm6vjx43rggQfs+1xcXHTvvfdmua111Y4dO+Ts7KzIyMgc133w4EGlpKSocePGDu2XLl3S3XffLUnau3evQx2SFBERkeM5rpo3b54mT56s+Ph4JScn6/Lly/L19XXoU758eZUtW9ZhnszMTO3bt08+Pj6Kj49Xt27d1L17d3ufy5cvy8/PL9f1ACYi8ADIVw0aNNDUqVPl6uqqMmXKyMXF8ceOl5eXw3ZycrLuuecexcXFZRmrRIkSf6sGDw+PXB+TnJwsSVqyZIlD0JCurEvKK5s2bVJUVJRGjBihJk2ayM/PT5988onGjx+f61qnT5+eJYA5OzvnWa3A7YzAAyBfeXl5KTQ0NMf9a9WqpXnz5qlkyZJZrnJcVbp0aW3evFn16tWTdOVKxrZt21SrVq1s+1evXl2ZmZlas2aNGjVqlGX/1StMGRkZ9rbw8HC5ubnp6NGj170yVLVqVfsC7Ku+++67vz7JP9m4caOCg4P16quv2tt++eWXLP2OHj2qY8eOqUyZMvZ5nJycFBYWplKlSqlMmTI6dOiQoqKicjU/8E/BomUAhUpUVJSKFy+uli1bat26dTp8+LBWr16tPn366LfffpMk9e3bV//+97+1aNEi/fzzz3r++edv+B46ISEhio6O1jPPPKNFixbZx/z0008lScHBwbLZbPrqq690+vRpJScny8fHRwMGDFD//v01a9YsxcfHa/v27ZoyZYp9IXDPnj114MABDRw4UPv27dPcuXM1c+bMXJ1v5cqVdfToUX3yySeKj4/X5MmTs12A7e7urujoaO3cuVPr1q1Tnz591K5dOwUGBkqSRowYobFjx2ry5Mnav3+/du/erRkzZuitt97KVT2AqQg8AAoVT09PrV27VuXLl1ebNm1UtWpVdevWTampqfYrPi+99JKefvppRUdHKyIiQj4+PmrduvUNx506daqefPJJPf/887rjjjvUvXt3XbhwQZJUtmxZjRgxQoMHD1apUqXUq1cvSdKoUaM0dOhQjR07VlWrVlXTpk21ZMkSVahQQdKVdTXz58/XokWLVKNGDU2bNk2vvfZars738ccfV//+/dWrVy/VrFlTGzdu1NChQ7P0Cw0NVZs2bdSsWTM98sgjuuuuuxweO4+JidH777+vGTNmqHr16oqMjNTMmTPttQL/dDbreqv8AAAADMEVHgAAYDwCDwAAMB6BBwAAGI/AAwAAjEfgAQAAxiPwAAAA4xF4AACA8Qg8AADAeAQeAABgPAIPAAAwHoEHAAAY7/8ACensk/YFx5IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(answers,y_preds,['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:51:20.940611Z",
     "iopub.status.busy": "2024-06-23T03:51:20.939873Z",
     "iopub.status.idle": "2024-06-23T03:51:26.903008Z",
     "shell.execute_reply": "2024-06-23T03:51:26.902042Z",
     "shell.execute_reply.started": "2024-06-23T03:51:20.940580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7594171352560615"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result = trainer_distilbert.predict(test_dataset)\n",
    "answers = np.argmax(val_result.label_ids,axis=1)\n",
    "y_preds = np.argmax(val_result.predictions,axis=1)\n",
    "accuracy_score(answers,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:51:29.450616Z",
     "iopub.status.busy": "2024-06-23T03:51:29.449803Z",
     "iopub.status.idle": "2024-06-23T03:51:29.632944Z",
     "shell.execute_reply": "2024-06-23T03:51:29.631722Z",
     "shell.execute_reply.started": "2024-06-23T03:51:29.450583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(answers,y_preds,['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(dict(X_test_tokenized), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(dict(X_test_tokenized))\n",
    "prediction_probs = tf.nn.softmax(y_preds.logits,axis=1).numpy()\n",
    "y_predictions = np.argmax(prediction_probs, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 5.3\n",
    "\n",
    "- BERT 모델, ALBERT 모델, DistillBERT 모델의 크기와 성능을 비교하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:15:12.438689Z",
     "iopub.status.busy": "2024-06-23T04:15:12.437709Z",
     "iopub.status.idle": "2024-06-23T04:15:12.650881Z",
     "shell.execute_reply": "2024-06-23T04:15:12.649589Z",
     "shell.execute_reply.started": "2024-06-23T04:15:12.438629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_distilBERT.save_pretrained('distilbert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:15:58.792730Z",
     "iopub.status.busy": "2024-06-23T05:15:58.792343Z",
     "iopub.status.idle": "2024-06-23T05:15:58.867224Z",
     "shell.execute_reply": "2024-06-23T05:15:58.866213Z",
     "shell.execute_reply.started": "2024-06-23T05:15:58.792697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "albert_model.save_pretrained('albert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:17:39.123167Z",
     "iopub.status.busy": "2024-06-23T04:17:39.122481Z",
     "iopub.status.idle": "2024-06-23T04:17:39.130942Z",
     "shell.execute_reply": "2024-06-23T04:17:39.129966Z",
     "shell.execute_reply.started": "2024-06-23T04:17:39.123133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28396034"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_distilBERT.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:19:44.834897Z",
     "iopub.status.busy": "2024-06-23T04:19:44.834277Z",
     "iopub.status.idle": "2024-06-23T04:19:46.159930Z",
     "shell.execute_reply": "2024-06-23T04:19:46.158646Z",
     "shell.execute_reply.started": "2024-06-23T04:19:44.834863Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92cc6626a8d4e62970ced69bff0c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26d55b7c6284fe698fe88ec82a86473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/53.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at kykim/albert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertForSequenceClassification\n",
    "model_albert = AlbertForSequenceClassification.from_pretrained(\"kykim/albert-kor-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:27:15.428953Z",
     "iopub.status.busy": "2024-06-23T04:27:15.428210Z",
     "iopub.status.idle": "2024-06-23T04:27:18.777781Z",
     "shell.execute_reply": "2024-06-23T04:27:18.776737Z",
     "shell.execute_reply.started": "2024-06-23T04:27:15.428919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f90116885984dc4926ad09b200e675d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600580853d7d43548f8c605c3ea7392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model_vanila_bert = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:21:15.896433Z",
     "iopub.status.busy": "2024-06-23T04:21:15.895738Z",
     "iopub.status.idle": "2024-06-23T04:21:15.902429Z",
     "shell.execute_reply": "2024-06-23T04:21:15.901358Z",
     "shell.execute_reply.started": "2024-06-23T04:21:15.896402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:27:48.095012Z",
     "iopub.status.busy": "2024-06-23T04:27:48.094166Z",
     "iopub.status.idle": "2024-06-23T04:27:48.105032Z",
     "shell.execute_reply": "2024-06-23T04:27:48.104081Z",
     "shell.execute_reply.started": "2024-06-23T04:27:48.094979Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBERT model parameters:  13188354\n",
      "DistilBERT model parameters:  28396034\n",
      "BERT model parameters:  177854978\n"
     ]
    }
   ],
   "source": [
    "num_params_distilBERT = count_parameters(model_distilBERT)\n",
    "num_params_albert = count_parameters(model_albert)\n",
    "num_params_bert = count_parameters(model_vanila_bert)\n",
    "print(\"ALBERT model parameters: \", num_params_albert)\n",
    "print(\"DistilBERT model parameters: \", num_params_distilBERT)\n",
    "print(\"BERT model parameters: \", num_params_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:57:13.277849Z",
     "iopub.status.busy": "2024-06-23T05:57:13.276690Z",
     "iopub.status.idle": "2024-06-23T05:58:16.583920Z",
     "shell.execute_reply": "2024-06-23T05:58:16.582967Z",
     "shell.execute_reply.started": "2024-06-23T05:57:13.277814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158cc429366d4a8cb82eecfdc74394d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d25000546e14b18a3092165c82bf1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8c8db9d27b486d8462def270f4b8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer= BertTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "X_train_tokenized_test = tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_val_tokenized_test = tokenizer(X_val, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "X_test_tokenized_test = tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\n",
    "\n",
    "train_dataset_df_test = make_dataset(X_train_tokenized_test, y_train)\n",
    "val_dataset_df_test = make_dataset(X_val_tokenized_test, y_val)\n",
    "test_dataset_df_test = make_dataset(X_test_tokenized_test, y_test)\n",
    "\n",
    "train_dataset_test = Dataset.from_pandas(train_dataset_df_test)\n",
    "val_dataset_test = Dataset.from_pandas(val_dataset_df_test)\n",
    "test_dataset_test = Dataset.from_pandas(test_dataset_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-23T05:59:37.374863Z",
     "iopub.status.busy": "2024-06-23T05:59:37.374487Z",
     "iopub.status.idle": "2024-06-23T05:59:37.382344Z",
     "shell.execute_reply": "2024-06-23T05:59:37.381467Z",
     "shell.execute_reply.started": "2024-06-23T05:59:37.374834Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 132307\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#계속 데이터셋변수명 같은 이름 써서 파이프 오류 뜸..세션 끄고 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:00:28.185663Z",
     "iopub.status.busy": "2024-06-23T06:00:28.184943Z",
     "iopub.status.idle": "2024-06-23T06:00:32.653483Z",
     "shell.execute_reply": "2024-06-23T06:00:32.652329Z",
     "shell.execute_reply.started": "2024-06-23T06:00:28.185626Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5fbc336b7a453f9e7217938fedd9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model_vanila_bert = BertForSequenceClassification.from_pretrained(\"kykim/bert-kor-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:22:15.201315Z",
     "iopub.status.busy": "2024-06-23T06:22:15.200888Z",
     "iopub.status.idle": "2024-06-23T06:22:15.735998Z",
     "shell.execute_reply": "2024-06-23T06:22:15.735123Z",
     "shell.execute_reply.started": "2024-06-23T06:22:15.201283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x78a0fadac5b0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 78a0a8761f00, raw_cell=\"from transformers import Trainer\n",
      "from transformers..\" store_history=True silent=False shell_futures=True cell_id=30c3d209-0a9f-49dc-8c2c-2ab0e4023cc4>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:437\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:706\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:363\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x78a0fadac5b0>> (for post_run_cell), with arguments args (<ExecutionResult object at 78a0a8761cf0, execution_count=16 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 78a0a8761f00, raw_cell=\"from transformers import Trainer\n",
      "from transformers..\" store_history=True silent=False shell_futures=True cell_id=30c3d209-0a9f-49dc-8c2c-2ab0e4023cc4> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:432\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:698\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"bert_model\",\n",
    "                                  num_train_epochs=2,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  per_device_eval_batch_size= 32,\n",
    "                                  weight_decay = 0.01,\n",
    "                                 evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer_bert = Trainer(\n",
    "    model=model_vanila_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_test,\n",
    "    eval_dataset=val_dataset_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-23T06:01:41.376145Z",
     "iopub.status.busy": "2024-06-23T06:01:41.375769Z",
     "iopub.status.idle": "2024-06-23T06:19:43.596010Z",
     "shell.execute_reply": "2024-06-23T06:19:43.594421Z",
     "shell.execute_reply.started": "2024-06-23T06:01:41.376116Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240623_060149-70obr4an</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyunju/huggingface/runs/70obr4an' target=\"_blank\">bert_model</a></strong> to <a href='https://wandb.ai/hyunju/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyunju/huggingface' target=\"_blank\">https://wandb.ai/hyunju/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyunju/huggingface/runs/70obr4an' target=\"_blank\">https://wandb.ai/hyunju/huggingface/runs/70obr4an</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7501' max='8270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7501/8270 17:28 < 01:47, 7.15 it/s, Epoch 1.81/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.214283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:424] . unexpected pos 588416384 vs 588416272",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/203: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer_albert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2732\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2815\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2814\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 2815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2816\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   2817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2925\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   2920\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   2921\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   2922\u001b[0m     )\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2924\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2925\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   2930\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 588416384 vs 588416272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 99, in _run\n",
      "    self._process(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 278, in _process\n",
      "    self._hm.handle(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 150, in handle\n",
      "    handler(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 158, in handle_request\n",
      "    logger.debug(f\"handle_request: {request_type}\")\n",
      "Message: 'handle_request: stop_status'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 99, in _run\n",
      "    self._process(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 327, in _process\n",
      "    self._sm.send(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 385, in send\n",
      "    send_handler(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 405, in send_request\n",
      "    logger.debug(f\"send_request: {request_type}\")\n",
      "Message: 'send_request: stop_status'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 199, in run\n",
      "    self.dispatch_events(self.event_queue, self.timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n",
      "    handler.dispatch(event)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n",
      "    _method_map[event_type](event)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 271, in _on_file_created\n",
      "    logger.info(\"file/dir created: %s\", event.src_path)\n",
      "Message: 'file/dir created: %s'\n",
      "Arguments: ('/kaggle/working/wandb/run-20240623_060149-70obr4an/files/output.log',)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 99, in _run\n",
      "    self._process(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 278, in _process\n",
      "    self._hm.handle(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 150, in handle\n",
      "    handler(record)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 158, in handle_request\n",
      "    logger.debug(f\"handle_request: {request_type}\")\n",
      "Message: 'handle_request: status_report'\n",
      "Arguments: ()\n",
      "Exception in thread OutRawRd-stderr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "--- Logging error ---\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1230, in _output_raw_reader_thread\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "    self._output_raw_flush(stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1245, in _output_raw_flush\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 281, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 882, in finish\n",
      "    logger.info(\"shutting down handler\")\n",
      "Message: 'shutting down handler'\n",
      "Arguments: ()\n",
      "    self._output_raw_file.write(data.encode(\"utf-8\"))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 128, in write\n",
      "    super().write(b\"\\n\".join(ret) + b\"\\n\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 95, in write\n",
      "    self.f.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 199, in run\n",
      "    self.dispatch_events(self.event_queue, self.timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n",
      "    handler.dispatch(event)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n",
      "    _method_map[event_type](event)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 288, in _on_file_modified\n",
      "    logger.info(f\"file/dir modified: { event.src_path}\")\n",
      "Message: 'file/dir modified: /kaggle/working/wandb/run-20240623_060149-70obr4an/files/output.log'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 330, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1545, in finish\n",
      "    logger.info(\"shutting down sender\")\n",
      "Message: 'shutting down sender'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 49, in run\n",
      "    self._target(**self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 173, in wandb_internal\n",
      "    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\n",
      "Message: 'Thread SenderThread:'\n",
      "Arguments: ()\n",
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 330, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1548, in finish\n",
      "    self._output_raw_finish()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1198, in _output_raw_finish\n",
      "    self._output_raw_flush(stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1245, in _output_raw_flush\n",
      "    self._output_raw_file.write(data.encode(\"utf-8\"))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 128, in write\n",
      "    super().write(b\"\\n\".join(ret) + b\"\\n\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 94, in write\n",
      "    self.f.write(*args, **kargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n"
     ]
    }
   ],
   "source": [
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 5.4 - Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 - 프롬프트 작성 원칙\n",
    "모델이 최대한 정확하고 유용한 정보를 제공할 수 있도록 효과적인 프롬프트를 작성하는 것이 매우 중요합니다. 좋은 프롬프트를 만들기 위해서 다음과 같은 원칙을 고려합니다.\n",
    "\n",
    "1. 명확성과 구체성\n",
    "질문은 명확하고 구체적이어야 합니다. 모호한 질문은 LLM 모델의 혼란을 초래할 수 있기 때문입니다.\n",
    "예시: \"다음 주 주식 시장에 영향을 줄 수 있는 예정된 이벤트들은 무엇일까요?\"는 \"주식 시장에 대해 알려주세요.\"보다 더 구체적이고 명확한 질문입니다.\n",
    "2. 배경 정보를 포함\n",
    "모델이 문맥을 이해할 수 있도록 필요한 배경 정보를 제공하는 것이 좋습니다. 이는 환각 현상(hallucination)이 발생할 위험을 낮추고, 관련성 높은 응답을 생성하는 데 도움을 줍니다.\n",
    "예시: \"2020년 미국 대선의 결과를 바탕으로 현재 정치 상황에 대한 분석을 해주세요.\"\n",
    "3. 간결함\n",
    "핵심 정보에 초점을 맞추고, 불필요한 정보는 배제합니다. 프롬프트가 길어지면 모델이 덜 중요한 부분에 집중하거나 상당한 영향을 받는 문제가 발생할 수 있습니다.\n",
    "예시: \"2021년에 발표된 삼성전자의 ESG 보고서를 요약해주세요.\"\n",
    "4. 열린 질문 사용\n",
    "열린 질문을 통해 모델이 자세하고 풍부한 답변을 제공하도록 유도합니다. 단순한 '예' 또는 '아니오'로 대답할 수 있는 질문보다는 더 많은 정보를 제공하는 질문이 좋습니다.\n",
    "예시: \"신재생에너지에 대한 최신 연구 동향은 무엇인가요?\"\n",
    "5. 명확한 목표 설정\n",
    "얻고자 하는 정보나 결과의 유형을 정확하게 정의합니다. 이는 모델이 명확한 지침에 따라 응답을 생성하도록 돕습니다.\n",
    "예시: \"AI 윤리에 대한 문제점과 해결 방안을 요약하여 설명해주세요.\"\n",
    "6. 언어와 문체\n",
    "대화의 맥락에 적합한 언어와 문체를 선택합니다. 이는 모델이 상황에 맞는 표현을 선택하는데 도움이 됩니다.\n",
    "예시: 공식적인 보고서를 요청하는 경우, \"XX 보고서에 대한 전문적인 요약을 부탁드립니다.\"와 같이 정중한 문체를 사용합니다.\n",
    "\n",
    "### 예시: 제품 리뷰 요약\n",
    "* 지시: \"아래 제공된 제품 리뷰를 요약해주세요.\"\n",
    "* 예시: \"예를 들어, '이 제품은 매우 사용하기 편리하며 배터리 수명이 길다'라는 리뷰는 '사용 편리성과 긴 배터리 수명이 특징'으로 요약할 수 있습니다.\"\n",
    "* 맥락: \"리뷰는 스마트워치에 대한 것이며, 사용자 경험에 초점을 맞추고 있습니다.\"\n",
    "* 질문: \"이 리뷰를 바탕으로 스마트워치의 주요 장점을 두세 문장으로 요약해주세요.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 openai langchain 시스템 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-23T06:36:07.045004Z",
     "iopub.status.busy": "2024-06-23T06:36:07.044649Z",
     "iopub.status.idle": "2024-06-23T06:36:23.661324Z",
     "shell.execute_reply": "2024-06-23T06:36:23.660371Z",
     "shell.execute_reply.started": "2024-06-23T06:36:07.044975Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_core\n",
      "  Downloading langchain_core-0.2.9-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain_core)\n",
      "  Downloading langsmith-0.1.81-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain_core)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (2.5.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (8.2.3)\n",
      "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n",
      "  Downloading openai-1.35.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain_core)\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.14.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (1.26.18)\n",
      "Downloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: packaging, orjson, tiktoken, openai, langsmith, langchain_core, langchain_openai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: orjson\n",
      "    Found existing installation: orjson 3.9.10\n",
      "    Uninstalling orjson-3.9.10:\n",
      "      Successfully uninstalled orjson-3.9.10\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.4.1 requires cubinlinker, which is not installed.\n",
      "cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.4.1 requires ptxcompiler, which is not installed.\n",
      "cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\n",
      "cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n",
      "distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain_core-0.2.9 langchain_openai-0.1.9 langsmith-0.1.81 openai-1.35.3 orjson-3.10.5 packaging-24.1 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "# openai langchain 시스템 이용하기\n",
    "!pip install langchain_core langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 템플릿 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:37:55.712818Z",
     "iopub.status.busy": "2024-06-23T06:37:55.712465Z",
     "iopub.status.idle": "2024-06-23T06:37:56.410799Z",
     "shell.execute_reply": "2024-06-23T06:37:56.409899Z",
     "shell.execute_reply.started": "2024-06-23T06:37:55.712790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문자열 템플릿 - 다음 예제는 langchain_core.prompts 모듈의 PromptTemplate 클래스를 사용하여, 'name'과 'age'라는 두 개의 변수를 포함하는 프롬프트 템플릿을 정의하고 있습니다. \n",
    "#이 템플릿을 이용하여 실제 입력값을 해당 위치에 채워 넣어 완성된 프롬프트를 생성하는 과정을 보여줍니다.\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\n",
    "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(name=\"홍길동\", age=30)\n",
    "\n",
    "filled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(filled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:38:07.921209Z",
     "iopub.status.busy": "2024-06-23T06:38:07.920214Z",
     "iopub.status.idle": "2024-06-23T06:38:07.929384Z",
     "shell.execute_reply": "2024-06-23T06:38:07.928342Z",
     "shell.execute_reply.started": "2024-06-23T06:38:07.921164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['age', 'language', 'name'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n",
    "              + \"\\n\\n{language}로 번역해주세요.\"\n",
    ")\n",
    "\n",
    "combined_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T15:45:37.196578Z",
     "iopub.status.busy": "2024-06-21T15:45:37.196189Z",
     "iopub.status.idle": "2024-06-21T15:45:37.204921Z",
     "shell.execute_reply": "2024-06-21T15:45:37.203896Z",
     "shell.execute_reply.started": "2024-06-21T15:45:37.196546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(combined_prompt.format(name=\"홍길동\", age=30, language=\"영어\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 ChatOpenAI 인스턴스 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:38:11.230189Z",
     "iopub.status.busy": "2024-06-23T06:38:11.229361Z",
     "iopub.status.idle": "2024-06-23T06:38:12.075092Z",
     "shell.execute_reply": "2024-06-23T06:38:12.074093Z",
     "shell.execute_reply.started": "2024-06-23T06:38:11.230159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my name is Hong Gil-dong and I am 30 years old.\\n\\nI cannot call my father \"father.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatOpenAI 인스턴스를 생성하여 프롬프트 텍스트를 전달하고, 모델의 출력을 StrOutputParser를 통해 문자열로 변환하는 LLM 체인을 구성합니다.\n",
    "# invoke 메소드를 사용하여 파이프라인을 실행하고, 최종적으로 문자열 출력을 얻습니다. 모델의 응답은 프롬프트에 주어진 문장을 영어로 번역한 텍스트가 출력됩니다.\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",\n",
    "                 temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "                 max_tokens=2048,  # 최대 토큰수\n",
    "                 \n",
    "                 # 본 토큰은 2024학년도 1학기 텍스트마이닝/자연어처리 수업의 과제 5를 위해서만 사용이 가능합니다.\n",
    "                 # 본 API는 6월 종강 시 까지 유지될 예정 입니다.\n",
    "                 # 본 API를 사용하는 모든 책임은 본인에게 있습니다.\n",
    "                 openai_api_key=\"________________\")\n",
    "                \n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"age\":30, \"language\":\"영어\", \"name\":\"홍길동\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.5 튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:38:15.599840Z",
     "iopub.status.busy": "2024-06-23T06:38:15.599472Z",
     "iopub.status.idle": "2024-06-23T06:38:19.484263Z",
     "shell.execute_reply": "2024-06-23T06:38:19.483343Z",
     "shell.execute_reply.started": "2024-06-23T06:38:15.599809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='세종대학교의 텍스트마이닝 수업은 자연어 처리와 통계적 분석 기법을 활용하여 대량의 텍스트 데이터로부터 유의미한 정보를 추출하는 방법을 다루는 수업입니다. 이 수업에서는 텍스트 데이터 전처리, 토큰화, 형태소 분석, 토픽 모델링, 감성 분석, 텍스트 분류 등 다양한 주제를 다루며, 실제 데이터를 활용하여 프로젝트를 수행하는 경험도 제공됩니다. 텍스트마이닝 수업을 통해 학생들은 텍스트 데이터를 다루는 기본적인 기술과 분석 능력을 향상시킬 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 237, 'prompt_tokens': 73, 'total_tokens': 310}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4d715ec0-e561-48c7-ba64-fb1e83faf3d1-0', usage_metadata={'input_tokens': 73, 'output_tokens': 237, 'total_tokens': 310})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 대학교의 수업에 대한 내용을 답변할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "\n",
    "chain.invoke({\"user_input\": \"세종대학교의 텍스트마이닝 수업에 대해 알려줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | llm\n",
    "chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.6 Model Paramter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 모델 파라미터 설정\n",
    "params = {\n",
    "    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n",
    "    \"max_tokens\": 100,          # 생성할 최대 토큰 수    \n",
    "}\n",
    "\n",
    "kwargs = {\n",
    "    \"frequency_penalty\": 0.5,   # 이미 등장한 단어의 재등장 확률\n",
    "    \"presence_penalty\": 0.5,    # 새로운 단어의 도입을 장려\n",
    "    \"stop\": [\"\\n\"]              # 정지 시퀀스 설정\n",
    "\n",
    "}\n",
    "\n",
    "# 모델 인스턴스를 생성할 때 파라미터 설정\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", \n",
    "                   \n",
    "                   # 본 토큰은 2024학년도 1학기 텍스트마이닝/자연어처리 수업의 과제 5를 위해서만 사용이 가능합니다.\n",
    "                   # 본 API는 6월 종강 시 까지 유지될 예정 입니다.\n",
    "                   # 본 API를 사용하는 모든 책임은 본인에게 있습니다.\n",
    "                   openai_api_key=\"______________________\",\n",
    "                   \n",
    "                   # user-defined hyperparamters\n",
    "                   **params, model_kwargs = kwargs)\n",
    "\n",
    "\n",
    "# 모델 호출\n",
    "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
    "response = model.invoke(input=question)\n",
    "\n",
    "# 전체 응답 출력\n",
    "print(response)\n",
    "print()\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 및 과제 5.4 \n",
    "\n",
    "나만의 프롬프트를 이용하여 본인이 원하는 분야의 특정 시스템을 정의(1)하고 파라미터 값을 조정하고 해당 시스템에 대한 예시 질문을 5개 정도 만들어 langchain 모델을 최적화 하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:51:34.108006Z",
     "iopub.status.busy": "2024-06-23T06:51:34.107611Z",
     "iopub.status.idle": "2024-06-23T06:51:34.139775Z",
     "shell.execute_reply": "2024-06-23T06:51:34.138981Z",
     "shell.execute_reply.started": "2024-06-23T06:51:34.107976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"temperature\": 0.4,         # 생성된 텍스트의 다양성 조정\n",
    "    \"max_tokens\": 250,          # 생성할 최대 토큰 수    \n",
    "}\n",
    "\n",
    "kwargs = {\n",
    "    \"frequency_penalty\": 0.4,   # 이미 등장한 단어의 재등장 확률\n",
    "    \"presence_penalty\": 0.4,    # 새로운 단어의 도입을 장려          # 정지 시퀀스 설정\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", \n",
    "                   \n",
    "                   # 본 토큰은 2024학년도 1학기 텍스트마이닝/자연어처리 수업의 과제 5를 위해서만 사용이 가능합니다.\n",
    "                   # 본 API는 6월 종강 시 까지 유지될 예정 입니다.\n",
    "                   # 본 API를 사용하는 모든 책임은 본인에게 있습니다.\n",
    "                   openai_api_key=\"__________________\",\n",
    "                   \n",
    "                   # user-defined hyperparamters\n",
    "                   **params, model_kwargs = kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-23T07:21:53.602866Z",
     "iopub.status.busy": "2024-06-23T07:21:53.602178Z",
     "iopub.status.idle": "2024-06-23T07:21:55.546077Z",
     "shell.execute_reply": "2024-06-23T07:21:55.545167Z",
     "shell.execute_reply.started": "2024-06-23T07:21:53.602824Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Request for Career Counseling Appointment\\n\\nDear Ms. Sung,\\n\\nI hope this email finds you well. My name is [학생의 이름] and I am a student majoring in Computer Science at [대학 이름]. I am writing to request an appointment with you for career counseling.\\n\\nAs I am approaching the end of my studies, I believe it would be beneficial for me to discuss my career options and seek guidance on potential paths in the field of computer science. Your expertise and experience would be invaluable in helping me make informed decisions about my future.\\n\\nI am available to meet at your convenience. Please let me know your availability so that we can schedule a meeting. Thank you for considering my request.\\n\\nI look forward to hearing from you soon.\\n\\nBest regards,\\n[학생의 이름]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_who = \"{who}가 {whom}에게 보내는 메일을 작성하고자 합니다.\"\n",
    "template_context = \"{context}는 상황입니다.\"\n",
    "prompt_template_who = PromptTemplate.from_template(template_who)\n",
    "prompt_template_context = PromptTemplate.from_template(template_context)\n",
    "\n",
    "combined_prompt = (\n",
    "              prompt_template_who\n",
    "              + prompt_template_context\n",
    "              + \"\\n\\n영어로 번역하여 제목과 본문을 포함해 이메일을 작성해 주세요.\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 주어진 상황에서 지정한 언어로 이메일을 작성해 줍니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"user_input\": combined_prompt.format(who=\"컴퓨터공학과 학생\",whom=\"지도 교수님 Ms.Sung\",context=\"진로 상담을 위해 면담을 신청하는\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:23:24.964660Z",
     "iopub.status.busy": "2024-06-23T07:23:24.963942Z",
     "iopub.status.idle": "2024-06-23T07:23:26.469144Z",
     "shell.execute_reply": "2024-06-23T07:23:26.468160Z",
     "shell.execute_reply.started": "2024-06-23T07:23:24.964629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제목: Inquiry about Assignment Deadline\\n\\n본문:\\nDear Mr. Brown,\\n\\nI hope this email finds you well. I am currently enrolled in the English conversation course and I am writing to inquire about the deadline for the upcoming assignment.\\n\\nCould you please confirm when the assignment is due? I want to make sure that I manage my time effectively to complete it on time.\\n\\nThank you for your attention to this matter. I look forward to hearing from you soon.\\n\\nBest regards,\\n[Your Name]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": combined_prompt.format(who=\"영어회화 강좌를 수강 중인 학생\",whom=\"과목 교수님 Mr.Brown\",context=\"과제 기한에 대해 문의하는\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:23:33.254908Z",
     "iopub.status.busy": "2024-06-23T07:23:33.254124Z",
     "iopub.status.idle": "2024-06-23T07:23:35.200907Z",
     "shell.execute_reply": "2024-06-23T07:23:35.200009Z",
     "shell.execute_reply.started": "2024-06-23T07:23:33.254867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Inquiry about Cancellation Fee\\n\\nDear Hyatt Hotel Service Center,\\n\\nI hope this email finds you well. My name is [Your Name] and I have a reservation at your hotel for the upcoming weekend. Unfortunately, due to unforeseen circumstances, I may need to cancel my reservation.\\n\\nI would like to inquire about the cancellation policy and any associated fees that may apply. Could you please provide me with information regarding the cancellation fee and any steps I need to take to cancel my reservation?\\n\\nThank you for your attention to this matter. I appreciate your assistance and understanding.\\n\\nSincerely,\\n[Your Name]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": combined_prompt.format(who=\" Hyatt 호텔을 이용하고자 하는 투숙객\",whom=\"호텔 서비스센터 직원\",context=\"취소 수수료에 대해 묻는\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:23:38.916016Z",
     "iopub.status.busy": "2024-06-23T07:23:38.915128Z",
     "iopub.status.idle": "2024-06-23T07:23:41.154787Z",
     "shell.execute_reply": "2024-06-23T07:23:41.153724Z",
     "shell.execute_reply.started": "2024-06-23T07:23:38.915984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"제목: Inquiry about the Difficulty Level of Language Courses\\n\\n본문:\\nDear Admissions Officer,\\n\\nI hope this email finds you well. My name is [Your Name] and I am a prospective student interested in enrolling at your language school at the university. I am writing to inquire about the difficulty level of the language courses offered at your institution.\\n\\nAs I am considering various options for furthering my language skills, understanding the level of challenge presented by your courses is crucial for me to make an informed decision. Could you please provide me with more information regarding the intensity and complexity of the language programs available? Additionally, I would appreciate it if you could share any details about the teaching methods and support systems in place to help students succeed in their language studies.\\n\\nI look forward to hearing from you and learning more about the educational opportunities at your esteemed university's language school. Thank you for your time and assistance.\\n\\nWarm regards,\\n\\n[Your Name]\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": combined_prompt.format(who=\"스페인 대학의 어학원에 등록하고자 하는 학생\",whom=\"어학원 apply 담당 직원\",context=\"교육 과정의 난이도에 대해 문의하는\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:23:43.669619Z",
     "iopub.status.busy": "2024-06-23T07:23:43.668946Z",
     "iopub.status.idle": "2024-06-23T07:23:46.106917Z",
     "shell.execute_reply": "2024-06-23T07:23:46.106021Z",
     "shell.execute_reply.started": "2024-06-23T07:23:43.669586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"제목: Inquiry about Master's Student Admission Plan\\n\\n본문:\\nDear Professor [교수님 성함],\\n\\nI hope this email finds you well. My name is [학생 이름] and I am a prospective graduate student interested in pursuing a Master's degree in Natural Language Processing at [대학명]. I have come across your research work in the field of NLP and I am truly impressed by the innovative projects your lab has been working on.\\n\\nI am writing to inquire about the admission plan for Master's students for the upcoming academic year. Could you please provide me with information regarding the application process, required documents, and any specific research areas that your lab will be focusing on? Additionally, I would like to know if there are any opportunities for research assistantships or scholarships available for incoming students.\\n\\nI am very passionate about NLP and I believe that joining your research group would be a valuable opportunity for me to further develop my skills and contribute to cutting-edge research in the field. Your guidance and mentorship would be greatly appreciated as I embark on this academic journey.\\n\\nThank you very much for considering my inquiry. I look forward to hearing from you soon.\\n\\nBest regards,\\n\\n[학생 이름]\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": combined_prompt.format(who=\"자연어 처리 대학원에 진학하고자 하는 학생\",whom=\"관심있는 랩 교수님\",context=\"석사 학생 선발 계획에 대해 문의하는\")})"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8796889,
     "sourceId": 81369,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
