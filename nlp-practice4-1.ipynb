{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"11193983vIqRQ-jqAVmKTQ02WTmSUi5Jr","authorship_tag":"ABX9TyP/pzJdgVFVWIfUHJ7Rmh18"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d368953738f1404bb27f25dc8a0c2f7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a474f2c53be4069b78b351dde2dc911","IPY_MODEL_259d9422cf7642a68a22979d77b82a43","IPY_MODEL_6bfbb086282541f9ab427c3cabc19d5f"],"layout":"IPY_MODEL_47135b22d8ee46dc9918976febb1210e"}},"8a474f2c53be4069b78b351dde2dc911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd54aaddb9e24de1a107749cc30cbdb6","placeholder":"​","style":"IPY_MODEL_945ebe9419194d9490053015aa93392c","value":"tokenizer_config.json: 100%"}},"259d9422cf7642a68a22979d77b82a43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c80b6fc45beb4dba9787d6a54edf8a4a","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cb2e5f12543478a8e5509b2dc588666","value":48}},"6bfbb086282541f9ab427c3cabc19d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc47774297934942b983e911ffe5430f","placeholder":"​","style":"IPY_MODEL_adc899a2fc3046d9ab0d4d2da4dd1a5c","value":" 48.0/48.0 [00:00&lt;00:00, 3.57kB/s]"}},"47135b22d8ee46dc9918976febb1210e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd54aaddb9e24de1a107749cc30cbdb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"945ebe9419194d9490053015aa93392c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80b6fc45beb4dba9787d6a54edf8a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb2e5f12543478a8e5509b2dc588666":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc47774297934942b983e911ffe5430f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adc899a2fc3046d9ab0d4d2da4dd1a5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4389ee17d63b4de7a56465d5f860c802":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5a658782174474c8cdf8a1a8e5916af","IPY_MODEL_285fed2fcbe5407b9b5af412b147714c","IPY_MODEL_06cd0c23965e43fd926756c42d5d7c89"],"layout":"IPY_MODEL_845f860926bc407da6a648d8dbeb8b9c"}},"e5a658782174474c8cdf8a1a8e5916af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5c7367b204d4a699cc1ad2d966b4de6","placeholder":"​","style":"IPY_MODEL_bcd9e4e464ed4afa9a3e68d542f5c9b3","value":"vocab.txt: 100%"}},"285fed2fcbe5407b9b5af412b147714c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34348d12c4374c1d8305f5a95d3cdbf0","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59e67b826db94ddbb7a698d95cb8c901","value":231508}},"06cd0c23965e43fd926756c42d5d7c89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f13794db957f49b5a134db3f14f1df49","placeholder":"​","style":"IPY_MODEL_3d538950128b4be6996eed06043ca2a9","value":" 232k/232k [00:00&lt;00:00, 6.24MB/s]"}},"845f860926bc407da6a648d8dbeb8b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c7367b204d4a699cc1ad2d966b4de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcd9e4e464ed4afa9a3e68d542f5c9b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34348d12c4374c1d8305f5a95d3cdbf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e67b826db94ddbb7a698d95cb8c901":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f13794db957f49b5a134db3f14f1df49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d538950128b4be6996eed06043ca2a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9bc5366de034eee8c870494dc535f65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_177a554eafee487d8f4298a9c22256fd","IPY_MODEL_1dabb85e028b4d1ca20d01a2ceb13b79","IPY_MODEL_ffc3ae48c7684384b1c0462cd2ab939f"],"layout":"IPY_MODEL_288a34acd7014ec18f6a514691aeeff6"}},"177a554eafee487d8f4298a9c22256fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa4a970c46a45f89acfdfd4883681ab","placeholder":"​","style":"IPY_MODEL_e1a7072a54064518868732b95c1b6718","value":"tokenizer.json: 100%"}},"1dabb85e028b4d1ca20d01a2ceb13b79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56498a2b81c04ae9b355812b64ebc6f5","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3313ab9eaca546b7867b5173abf6320e","value":466062}},"ffc3ae48c7684384b1c0462cd2ab939f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6110764a36e049838174711b1796ae8a","placeholder":"​","style":"IPY_MODEL_19e0f42bf4b6437d8f4646d4ab2933a0","value":" 466k/466k [00:00&lt;00:00, 2.34MB/s]"}},"288a34acd7014ec18f6a514691aeeff6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fa4a970c46a45f89acfdfd4883681ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a7072a54064518868732b95c1b6718":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56498a2b81c04ae9b355812b64ebc6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3313ab9eaca546b7867b5173abf6320e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6110764a36e049838174711b1796ae8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19e0f42bf4b6437d8f4646d4ab2933a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19dff6d8e9ed449fa6ac4065f69944fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dc7bc4b696946fca5d6db8ebf0155c7","IPY_MODEL_5da51ee2cdba4e5eb1595138f1000285","IPY_MODEL_3abc272b7b644e568889748c6273b7de"],"layout":"IPY_MODEL_26854284628b4a1eb0cc72035a93cef4"}},"7dc7bc4b696946fca5d6db8ebf0155c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a361ba9246f48dba55252350c0fdb64","placeholder":"​","style":"IPY_MODEL_1057afb1bc1b4e5b9af9886da7072ddc","value":"config.json: 100%"}},"5da51ee2cdba4e5eb1595138f1000285":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1465f491235c43f4a753b55118eeb113","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8fbf1a92f504cd2965b4d9850152287","value":570}},"3abc272b7b644e568889748c6273b7de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08b713266ef94ca0bccfb7e50b194e70","placeholder":"​","style":"IPY_MODEL_73a6a2022d504adeb5f37d41d3eaeb87","value":" 570/570 [00:00&lt;00:00, 11.7kB/s]"}},"26854284628b4a1eb0cc72035a93cef4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a361ba9246f48dba55252350c0fdb64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1057afb1bc1b4e5b9af9886da7072ddc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1465f491235c43f4a753b55118eeb113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8fbf1a92f504cd2965b4d9850152287":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08b713266ef94ca0bccfb7e50b194e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a6a2022d504adeb5f37d41d3eaeb87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da0c5acc69974dc3aeee8dfde710f7d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac543b7cec9d4c94a8b14e1beeb26f3c","IPY_MODEL_c19a2bcf16ad444aba1608f538dd0422","IPY_MODEL_beb98947fedf4b5f8399326c18573ed9"],"layout":"IPY_MODEL_5ff4978f069f496db4ad21e472a9f617"}},"ac543b7cec9d4c94a8b14e1beeb26f3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d039b2107824cbb9c7ab58d8b674df4","placeholder":"​","style":"IPY_MODEL_51c17e80b7da484aa84c32d7fcf9be59","value":"model.safetensors: 100%"}},"c19a2bcf16ad444aba1608f538dd0422":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f86f1102e73e4945b3e5bf97daed06e4","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aaab1a165be74e1a95c08a363ffbebc8","value":440449768}},"beb98947fedf4b5f8399326c18573ed9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c9c90e6a85346589dbcdb062f214fc7","placeholder":"​","style":"IPY_MODEL_06476af5f1554d5e95c392fd03ec3733","value":" 440M/440M [00:04&lt;00:00, 107MB/s]"}},"5ff4978f069f496db4ad21e472a9f617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d039b2107824cbb9c7ab58d8b674df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51c17e80b7da484aa84c32d7fcf9be59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f86f1102e73e4945b3e5bf97daed06e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaab1a165be74e1a95c08a363ffbebc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c9c90e6a85346589dbcdb062f214fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06476af5f1554d5e95c392fd03ec3733":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","\n","*   SQuAD 데이터 살펴보기\n","\n"],"metadata":{"id":"kMSvT41JUosf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RA25ThYvQ3Ls","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717351044895,"user_tz":-540,"elapsed":3260,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"aa6b5cf4-1812-4698-c97c-e1429f32dd04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","\n","('56be85543aeaaa14008c9063',) ('When did Beyonce start becoming popular?',) {'text': 'in the late 1990s', 'answer_start': 269}\n","('56be85543aeaaa14008c9065',) ('What areas did Beyonce compete in when she was growing up?',) {'text': 'singing and dancing', 'answer_start': 207}\n","('56be85543aeaaa14008c9066',) (\"When did Beyonce leave Destiny's Child and become a solo singer?\",) {'text': '2003', 'answer_start': 526}\n","('56bf6b0f3aeaaa14008c9601',) ('In what city and state did Beyonce  grow up? ',) {'text': 'Houston, Texas', 'answer_start': 166}\n","('56bf6b0f3aeaaa14008c9602',) ('In which decade did Beyonce become famous?',) {'text': 'late 1990s', 'answer_start': 276}\n","('56bf6b0f3aeaaa14008c9603',) ('In what R&B group was she the lead singer?',) {'text': \"Destiny's Child\", 'answer_start': 320}\n","('56bf6b0f3aeaaa14008c9604',) ('What album made her a worldwide known artist?',) {'text': 'Dangerously in Love', 'answer_start': 505}\n","('56bf6b0f3aeaaa14008c9605',) (\"Who managed the Destiny's Child group?\",) {'text': 'Mathew Knowles', 'answer_start': 360}\n","('56d43c5f2ccc5a1400d830a9',) ('When did Beyoncé rise to fame?',) {'text': 'late 1990s', 'answer_start': 276}\n","('56d43c5f2ccc5a1400d830aa',) (\"What role did Beyoncé have in Destiny's Child?\",) {'text': 'lead singer', 'answer_start': 290}\n","('56d43c5f2ccc5a1400d830ab',) ('What was the first album Beyoncé released as a solo artist?',) {'text': 'Dangerously in Love', 'answer_start': 505}\n","('56d43c5f2ccc5a1400d830ac',) ('When did Beyoncé release Dangerously in Love?',) {'text': '2003', 'answer_start': 526}\n","('56d43c5f2ccc5a1400d830ad',) ('How many Grammy awards did Beyoncé win for her first solo album?',) {'text': 'five', 'answer_start': 590}\n","('56d43ce42ccc5a1400d830b4',) (\"What was Beyoncé's role in Destiny's Child?\",) {'text': 'lead singer', 'answer_start': 290}\n","('56d43ce42ccc5a1400d830b5',) (\"What was the name of Beyoncé's first solo album?\",) {'text': 'Dangerously in Love', 'answer_start': 505}\n"]}],"source":["import os\n","import json\n","\n","filename = \"/content/drive/MyDrive/Colab Notebooks/NLP/train-v2.json\"\n","\n","with open(filename, \"r\", encoding='utf-8') as reader:\n","    input_data = json.load(reader)[\"data\"]\n","\n","for entry in input_data:\n","    for paragraph in entry[\"paragraphs\"]:\n","        context = paragraph['context']\n","        print(context)\n","        print()\n","\n","        for qa in paragraph['qas']:\n","            is_impossible = qa['is_impossible']\n","\n","            if not is_impossible:\n","                answer = qa['answers'][0]\n","                original_answer = answer['text']\n","                answer_start = answer['answer_start']\n","\n","            qid=qa['id'],\n","            question=qa['question'],\n","\n","            print(qid, question, answer)\n","\n","\n","        break\n","    break"]},{"cell_type":"markdown","source":["SQuAD: 스탠퍼드 질문 답변 데이터셋(Stanford Question Answering Dataset)\n","컴퓨터가 텍스트 문단을 읽고 관련 질문에 답변이 가능한지 테스트할 때 많이 사용된다.\n","수백 개의 위키피디아 영어 문서에서 샘플링하고 크라우드 소싱을 통해 각 문단에서 일련의 질문과 답을 생성해 만들어짐.\n","SQuAD의 최초 버전은 각 질문의 답이 해당 구절 안에 반드시 존재했는데, 시퀀스 모델이 텍스트에서 정답을 추출하는 속도가 금세 사람을 앞지르기 시작했다. 작업의 난도를 높이기 위해 주어진 텍스트와 관련되지만 텍스트만으로는 답변할 수 없는 적대적인 질문(adversarial question)으로 SQuAD 1.1을 보강해 SQuAD 2.0을 만들었다.\n","더 어려운 벤치마크 NQ(Natural Question) 데이터셋도 있다. (구글)"],"metadata":{"id":"Wusj61LoYz-h"}},{"cell_type":"markdown","source":["### 실습 4.2 - SQuAD Dataset Class 생성 (from raw data to tokenized version)"],"metadata":{"id":"m9rHrFk9ZtxN"}},{"cell_type":"code","source":["'''\n","본문 데이터 전처리 방식\n","\n","Consider the context: \"Hello world\".\n","1. H is not whitespace, start a new token: doc_tokens = ['H']\n","2. e is not whitespace, continue the current token: doc_tokens = ['He']\n","3. l is not whitespace, continue the current token: doc_tokens = ['Hel']\n","4. l is not whitespace, continue the current token: doc_tokens = ['Hell']\n","5. o is not whitespace, continue the current token: doc_tokens = ['Hello']\n","6. (space) is whitespace, set prev_is_whitespace = True\n","7. w is not whitespace, start a new token: doc_tokens = ['Hello', 'w']\n","8. o is not whitespace, continue the current token: doc_tokens = ['Hello', 'wo']\n","9. r is not whitespace, continue the current token: doc_tokens = ['Hello', 'wor']\n","10. l is not whitespace, continue the current token: doc_tokens = ['Hello', 'worl']\n","11. d is not whitespace, continue the current token: doc_tokens = ['Hello', 'world']\n","\n","최종 결과물\n","doc_tokens = ['Hello', 'world']\n","char_to_word_offset = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","char_to_word_offset에 있는 각 인덱스는 원본 context에서 각 character의 위치(단어)를 표현함\n","segment embedding과 비슷한데 segment embedding은 각 word가 어떤 sentence에 속해있는지 나눠주고\n","이거는 각 character가 어떤 word에 속해있는지 나눠주는 역할?\n","\n","This preprocessing step ensures that each character in the context can be traced back to its token,\n","which is crucial for tasks like question answering where character-level annotations (e.g., start and end positions of answers)\n","need to be converted to token-level annotations.\n","'''"],"metadata":{"id":"-xwABsrSqzR8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","from torch.utils.data import Dataset, TensorDataset\n","\n","# import module we'll need to import our custom module\n","from shutil import copyfile\n","\n","# copy our file into the working directory (make sure it has .py suffix)\n","copyfile(src = \"/content/drive/MyDrive/Colab Notebooks/NLP/feature.py\", dst = \"/content/feature.py\")\n","from feature import convert_examples_to_features\n","\n","def is_whitespace(c):\n","    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n","        return True\n","    return False\n","\n","class SquadExample():\n","    def __init__(self, qid, context, question, answer, start, end, is_impossible):\n","        self.qid = qid\n","        self.context = context\n","        self.question = question\n","        self.answer = answer\n","        self.start = start\n","        self.end = end\n","        self.is_impossible = is_impossible\n","\n","    def __repr__(self):\n","        #return self.context[self.start:self.end]\n","        #if self.context[self.start:self.end] != self.answer:\n","        #    return 'NA!! {} - {}'.format(self.context[self.start:self.end], answer)\n","        return 'id:{}  question:{}...  answer:{}...  is_impossible:{}'.format(\n","            self.qid,\n","            self.question[:10],\n","            self.answer[:10],\n","            self.is_impossible)\n","\n","class SquadDataset(Dataset):\n","    def __init__(self, path, tokenizer, is_train=True, is_inference=False):\n","        '''\n","        path: SquadDataset 데이터셋 위치\n","        tokenizer: Squad 데이터셋을 토크나이징할 토크나이저, ex) BertTokenizer\n","        is_train: SquadDataset을 정의하는 목적이 모델 학습용일 경우 True, 그렇지 않으면 False\n","        is_inference: SquadDataset을 정의하는 목적이 인퍼런스용일 경우 True, 그렇지 않으면 False\n","        '''\n","\n","        if is_train:\n","            filename = os.path.join(path, 'train-v2.json')\n","        else:\n","            if is_inference:\n","                filename = os.path.join(path, 'test-v2.json')\n","            else:\n","                filename = os.path.join(path, 'dev-v2.json')\n","\n","        cached_features_file = os.path.join(os.path.dirname(filename), 'cached_{}_64.cache'.format('train' if is_train else 'valid'))\n","        #cached_examples_file = os.path.join(os.path.dirname(filename), 'cached_example_{}_64.cache'.format('train' if is_train else 'valid'))\n","\n","        if os.path.exists(cached_features_file):\n","            print('cache file exists')\n","            self.features = torch.load(cached_features_file)\n","        else:\n","            print('cache file does not exist')\n","\n","            with open(filename, \"r\", encoding='utf-8') as reader:\n","                input_data = json.load(reader)[\"data\"]\n","\n","            self.examples = []\n","            number_of_examples = 100\n","            for entry in input_data[:number_of_examples]:\n","                for paragraph in entry[\"paragraphs\"]:\n","                    context = paragraph['context'] #본문데이터\n","\n","                    doc_tokens = [] #store the tokens of the context.\n","                    char_to_word_offset = [] #map each character in the context to its corresponding token index in 'doc_tokens'\n","                    prev_is_whitespace = True #is usde to decide whether to start a new token or continue adding to the current token.\n","                    for c in context:\n","                        if is_whitespace(c):\n","                            prev_is_whitespace = True\n","                        else:\n","                            if prev_is_whitespace: #If the previous character was a whitespace, a new token is started by\n","                                doc_tokens.append(c) #appending 'c' to doc_tokens\n","                            else: #If the previous character was not a whitespace, the current character 'c' is appended\n","                                doc_tokens[-1] += c #to the last token in doc_tokens\n","                            prev_is_whitespace = False\n","                        char_to_word_offset.append(len(doc_tokens) - 1) #For each character 'c', char_to_word_offset recoreds the index of the current token in doc_tokens. This helps in mapping each character back to its corresponding token.\n","\n","\n","                    for qa in paragraph['qas']: #질문-답변들\n","                        is_impossible = qa['is_impossible']\n","\n","                        if not is_impossible:\n","                            answer = qa['answers'][0] #여러가지 답변이 있을 수 있는데 첫번째것만 사용\n","                            original_answer = answer['text'] #answer text\n","                            answer_start = answer['answer_start'] #본문 내 answer position\n","\n","                            answer_length = len(original_answer) #답변의 길이\n","                            start_pos = char_to_word_offset[answer_start] #starting position -- 몇 번째 word부터인지 확인가능\n","                            end_pos = char_to_word_offset[answer_start + answer_length - 1] #ending position -- 몇 번째 word까지인지\n","\n","                            answer_end = answer_start + len(original_answer)\n","                        else:\n","                            original_answer = ''\n","                            start_pos = 1\n","                            end_pos = -1\n","\n","                        example = SquadExample(\n","                            qid=qa['id'],\n","                            context=doc_tokens,\n","                            question=qa['question'],\n","                            answer=original_answer,\n","                            start=start_pos,\n","                            end=end_pos,\n","                            is_impossible=is_impossible)\n","                        self.examples.append(example)\n","            print('examples: {}'.format(len(self.examples)))\n","\n","            self.features = convert_examples_to_features(\n","                examples=self.examples,\n","                tokenizer=tokenizer,\n","                max_seq_length=384,\n","                doc_stride=128,\n","                max_query_length=64,\n","                is_training=True if not is_inference else False)\n","            print('is_training: {}'.format(True if not is_inference else False))\n","\n","            # torch.save(self.examples, cached_examples_file)\n","            # torch.save(self.features, cached_features_file)\n","\n","        '''\n","        # Convert to Tensors and build dataset\n","        all_input_ids = torch.tensor([f.input_ids for f in self.features], dtype=torch.long)\n","        all_input_mask = torch.tensor([f.input_mask for f in self.features], dtype=torch.long)\n","        all_segment_ids = torch.tensor([f.segment_ids for f in self.features], dtype=torch.long)\n","        all_cls_index = torch.tensor([f.cls_index for f in self.features], dtype=torch.long)\n","        all_p_mask = torch.tensor([f.p_mask for f in self.features], dtype=torch.float)\n","        if is_train:\n","            all_start_positions = torch.tensor([f.start_position for f in self.features], dtype=torch.long)\n","            all_end_positions = torch.tensor([f.end_position for f in self.features], dtype=torch.long)\n","            dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n","                                    all_start_positions, all_end_positions,\n","                                    all_cls_index, all_p_mask)\n","        else:\n","            all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","            dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index, all_cls_index, all_p_mask)\n","        return dataset\n","        '''\n","\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        return self.features[idx]"],"metadata":{"id":"UqGWlEVuZU_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqrckYT-n2vp","executionInfo":{"status":"ok","timestamp":1717208862025,"user_tz":-540,"elapsed":10349,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"ef9d94ea-6d05-4e26-e5b1-7b7dff69bea9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### 실습 4.3 - SQuAD DataLoader 생성 (from raw data to tokenized version)"],"metadata":{"id":"8a4ooca3mvpe"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader\n","\n","class SquadDataLoader(DataLoader):\n","    def __init__(self, dataset, batch_size, is_inference=False, shuffle=True):\n","        '''\n","        dataset: SquadDataset으로 정의한 데이터셋 객체\n","        batch_size: 배치 사이즈\n","        is_inference: SquadDataLoader를 인퍼런스 목적으로 사용할 경우 True, 그렇지 않으면 False\n","        shuffle: 데이터의 순서를 섞을 경우 True, 그렇지 않으면 False\n","        '''\n","        self.is_inference = is_inference\n","        super().__init__(dataset, collate_fn=self.squad_collate_fn, batch_size=batch_size, shuffle=shuffle)\n","\n","    def squad_collate_fn(self, features): #BERT 모델의 input으로 사용하기 위해 feature object들의 리스트를 받아서 텐서로 변환하는 함수\n","        #Input IDs --> creates a tensor of shape (batch_size, max_seq_length)\n","        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","        #Input Mask --> input_mask, typically 1 for real tokens and 0 for padding tokens\n","        all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","        #Segment IDs --> used to distinguish between segments in BERT's input, such as question and context\n","        all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","        #CLS Index --> The index of [CLS] token in the input sequence. creates a tensor of shape (batch_size,)\n","        all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n","        #P mask --> a mask that identifies tokens that can be answerable, often used in QA models to mask out unanswerable tokens\n","        all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n","\n","        # return 6 tensors\n","        if self.is_inference:\n","            all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","            return all_input_ids, all_input_mask, all_segment_ids, all_cls_index, all_p_mask, all_example_index\n","        # return 7 tensors\n","        else: #train용\n","            all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long)\n","            all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)\n","            return all_input_ids, all_input_mask, all_segment_ids, all_cls_index, all_p_mask, all_start_positions, all_end_positions"],"metadata":{"id":"by65Kv1cmu2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 실습 4.4 Load Dataset"],"metadata":{"id":"j17UN4EAm3Wt"}},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm, trange\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer\n","\n","path = \"/content/drive/MyDrive/Colab Notebooks/NLP\"\n","\n","print(\"Tokenizer Loading\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","#print(\"Dataset Loading\")\n","#train_dataset = SquadDataset(path, tokenizer, is_train=True) # 153,000\n","\n","#print(\"Data Loader\")\n","#train_dataloader = SquadDataLoader(train_dataset, batch_size=32, is_inference=False, shuffle=True)"],"metadata":{"id":"Bu-fg-pem2Cc","colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["d368953738f1404bb27f25dc8a0c2f7e","8a474f2c53be4069b78b351dde2dc911","259d9422cf7642a68a22979d77b82a43","6bfbb086282541f9ab427c3cabc19d5f","47135b22d8ee46dc9918976febb1210e","fd54aaddb9e24de1a107749cc30cbdb6","945ebe9419194d9490053015aa93392c","c80b6fc45beb4dba9787d6a54edf8a4a","7cb2e5f12543478a8e5509b2dc588666","bc47774297934942b983e911ffe5430f","adc899a2fc3046d9ab0d4d2da4dd1a5c","4389ee17d63b4de7a56465d5f860c802","e5a658782174474c8cdf8a1a8e5916af","285fed2fcbe5407b9b5af412b147714c","06cd0c23965e43fd926756c42d5d7c89","845f860926bc407da6a648d8dbeb8b9c","a5c7367b204d4a699cc1ad2d966b4de6","bcd9e4e464ed4afa9a3e68d542f5c9b3","34348d12c4374c1d8305f5a95d3cdbf0","59e67b826db94ddbb7a698d95cb8c901","f13794db957f49b5a134db3f14f1df49","3d538950128b4be6996eed06043ca2a9","b9bc5366de034eee8c870494dc535f65","177a554eafee487d8f4298a9c22256fd","1dabb85e028b4d1ca20d01a2ceb13b79","ffc3ae48c7684384b1c0462cd2ab939f","288a34acd7014ec18f6a514691aeeff6","7fa4a970c46a45f89acfdfd4883681ab","e1a7072a54064518868732b95c1b6718","56498a2b81c04ae9b355812b64ebc6f5","3313ab9eaca546b7867b5173abf6320e","6110764a36e049838174711b1796ae8a","19e0f42bf4b6437d8f4646d4ab2933a0"]},"executionInfo":{"status":"ok","timestamp":1717351127113,"user_tz":-540,"elapsed":1357,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"ef759bc9-56ad-4a8a-82c6-60a2346e897f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer Loading\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d368953738f1404bb27f25dc8a0c2f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4389ee17d63b4de7a56465d5f860c802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9bc5366de034eee8c870494dc535f65"}},"metadata":{}}]},{"cell_type":"markdown","source":["### 실습 4.5 - Load Pre-trained BERT\n","### 과제 4.1 - BERT for Question Answering 모델 이해하고 설명하기 / Tokenizer 변경해보기\n","\n","#### BERT for Question Answering 참고\n","#### https://huggingface.co/docs/transformers/v4.41.0/en/model_doc/bert#transformers.BertForQuestionAnswering\n","\n","#### BERT Tokenizer 참고\n","#### https://huggingface.co/docs/transformers/v4.41.0/en/model_doc/bert#transformers.BertTokenizer"],"metadata":{"id":"C-RQ7kF5qt1d"}},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tO3J6mUN5XsL","executionInfo":{"status":"ok","timestamp":1717314112196,"user_tz":-540,"elapsed":15,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"c85cbbd0-515d-4ed7-a14c-fff7c0a1bcff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.3.0+cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# pytoch model import from huggingface\n","from transformers import BertTokenizer, BertForQuestionAnswering, AdamW\n","\n","# GPU 이용 방법 - Notebook Option - Session Options - ACCELRATOR 설정 (GPU P100)\n","# .cuda() 옵션을 제거하면 cpu에서도 학습 가능\n","model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n","\n","model.train()"],"metadata":{"id":"zppfD3k4qthk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717346651324,"user_tz":-540,"elapsed":4859,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"8ab383d6-9c2b-4cb3-e77c-538eec1a0fc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def train(model, dataloader, optimizer):\n","  tbar = tqdm(dataloader, desc='Training', leave=True)\n","\n","  total_loss = 0.0\n","  for i, batch in enumerate(tbar):\n","    optimizer.zero_grad()\n","\n","    # cls_index와 p_mask는 XLNet 모델에 사용되므로 BERT에서는 사용하지 않는다.\n","    input_ids, input_mask, segment_ids, cls_index, p_mask, start_positions, end_positions = batch\n","\n","    input_ids = input_ids.cuda()\n","    input_mask = input_mask.cuda()\n","    segment_ids = segment_ids.cuda()\n","    start_positions = start_positions.cuda()\n","    end_positions = end_positions.cuda()\n","\n","    #train model\n","    #out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","    inputs = {\n","        'input_ids': input_ids,\n","        'token_type_ids': segment_ids,\n","        'attention_mask': input_mask,\n","    }\n","    out = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n","    loss = out.loss\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.data.item()\n","    tbar.set_description(\"Average Loss = {:.4f})\".format(total_loss/(i+1)))"],"metadata":{"id":"cBoluCYd1c1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Fine Tuning"],"metadata":{"id":"Vm4udD_L2j9b"}},{"cell_type":"code","source":["\"\"\"\n","Train (Fine-tune) your BERT with SQuAD dataset\n","\"\"\"\n","\n","optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n","loss = nn.CrossEntropyLoss()\n","n_epoch = 3\n","\n","# actual training\n","for i in range(n_epoch):\n","    train(model, train_dataloader, optimizer)\n","\n","\n","# save model\n","# torch.save(model.state_dict(), 'squad_model.bin')"],"metadata":{"id":"I8YNJP052i5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/squad_model.bin')"],"metadata":{"id":"ReU6W7Tq-wpV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 과제 4.2 Inference 및 Evaluate\n","\n","- 파인튜닝을 마치고 dev-v2.json 파일을 불러와 Inference를 위한 코드를 실행한다.\n","- 예측한 span과 정답 span을 비교해본다.\n","- F1을 이용하여 dev-v2.json의 샘플 1000개를 대상으로 예측한 span과 정답 span을 평가하는 코드를 작성한다.\n","\n","아래 평가용 코드 참고\n","\n","- https://github.com/jinkilee/hello-transformer/blob/master/research/chapter4/squad/run_evaluate.py\n","- https://github.com/jinkilee/hello-transformer/blob/master/research/chapter4/squad/evaluate.py"],"metadata":{"id":"bbLvcbLV96S-"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').cuda()\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP/squad_model.bin', map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257,"referenced_widgets":["19dff6d8e9ed449fa6ac4065f69944fb","7dc7bc4b696946fca5d6db8ebf0155c7","5da51ee2cdba4e5eb1595138f1000285","3abc272b7b644e568889748c6273b7de","26854284628b4a1eb0cc72035a93cef4","7a361ba9246f48dba55252350c0fdb64","1057afb1bc1b4e5b9af9886da7072ddc","1465f491235c43f4a753b55118eeb113","a8fbf1a92f504cd2965b4d9850152287","08b713266ef94ca0bccfb7e50b194e70","73a6a2022d504adeb5f37d41d3eaeb87","da0c5acc69974dc3aeee8dfde710f7d2","ac543b7cec9d4c94a8b14e1beeb26f3c","c19a2bcf16ad444aba1608f538dd0422","beb98947fedf4b5f8399326c18573ed9","5ff4978f069f496db4ad21e472a9f617","3d039b2107824cbb9c7ab58d8b674df4","51c17e80b7da484aa84c32d7fcf9be59","f86f1102e73e4945b3e5bf97daed06e4","aaab1a165be74e1a95c08a363ffbebc8","9c9c90e6a85346589dbcdb062f214fc7","06476af5f1554d5e95c392fd03ec3733"]},"id":"SCPHfXnjz7Pg","executionInfo":{"status":"ok","timestamp":1717351113962,"user_tz":-540,"elapsed":16134,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"611c5c82-939d-4690-a238-8a5303e644cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19dff6d8e9ed449fa6ac4065f69944fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0c5acc69974dc3aeee8dfde710f7d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["valid_dataset = SquadDataset(path, tokenizer, is_train=False) # 11,873\n","valid_dataloader = SquadDataLoader(valid_dataset, batch_size=32, is_inference=False, shuffle=True)"],"metadata":{"id":"TgDkSf8893oZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717351250911,"user_tz":-540,"elapsed":119025,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"1af032c9-ccaf-4c47-8a25-62e13c27e380"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cache file does not exist\n","examples: 11873\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 11873/11873 [01:57<00:00, 101.35it/s]"]},{"output_type":"stream","name":"stdout","text":["is_training: True\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["len(valid_dataset.examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Je-or62qf8O-","executionInfo":{"status":"ok","timestamp":1717340992874,"user_tz":-540,"elapsed":13,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"ec06ae7a-2c75-459d-bcc0-d7948e32ccc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11873"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["all_input_ids, all_input_mask, all_segment_ids, all_cls_index, all_p_mask, all_start_positions, all_end_positions = next(iter(valid_dataloader))\n","#print(tokenizer.decode(torch.tensor([all_input_ids[0][all_start_positions:all_end_positions+1]]), skip_special_tokens=True))"],"metadata":{"collapsed":true,"id":"pgc2WLjz3aIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\")"],"metadata":{"id":"y5gsqTARIHDF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = model(input_ids = all_input_ids[0].unsqueeze(0).to(device),token_type_ids=all_segment_ids[0].unsqueeze(0).to(device))"],"metadata":{"id":"6oBtcWWGHRJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NUeOhVAoIUlr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32"],"metadata":{"id":"6ZHpG5CzGS9L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습된 모델이 예측한 결과와 주어진 validation 데이터셋과 비교해본다.\n","import pandas as pd\n","def inference(model, tokenizer):\n","  answer_sheet = []\n","  num_batches = 3\n","  for i in range(num_batches):\n","    all_input_ids, all_input_mask, all_segment_ids, all_cls_index, all_p_mask, all_start_positions, all_end_positions = next(iter(valid_dataloader))\n","    for j in range(batch_size):\n","        input_ids = all_input_ids[j].unsqueeze(0).to(device)\n","        token_type_ids = all_segment_ids[j].unsqueeze(0).to(device)\n","        attention_mask = all_input_mask[j].unsqueeze(0).to(device)\n","        output = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","        predict_start_index = output.start_logits.argmax()\n","        predict_end_index = output.end_logits.argmax()\n","        predict_answer_tokens = all_input_ids[j][predict_start_index:predict_end_index+1]\n","        pred = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n","\n","        answ = tokenizer.decode(all_input_ids[j][all_start_positions[j]:all_end_positions[j]+1])\n","\n","        answer_sheet.append([answ, pred])\n","\n","  df = pd.DataFrame(answer_sheet, columns=['Answer', 'Prediction'])\n","  df.to_csv('/kaggle/working/answer.csv', index=False)\n","  print(df)\n","  return\n","\n","\"\"\"\n","Write your code here\n","pred:\n","answ:\n","추출해서\n","비교\n","\"\"\"\n"],"metadata":{"id":"zHPHLCxK93m7","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1717346838192,"user_tz":-540,"elapsed":316,"user":{"displayName":"HJ","userId":"04584162756684325171"}},"outputId":"3c1928f6-9591-4c98-e6e2-7a12ae1b01ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nWrite your code here\\npred:\\nansw:\\n추출해서\\n비교\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["inference(model, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Acd0oXTNsEQc","outputId":"648546fb-1318-415c-9d75-cb86e42e1183"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]}]},{"cell_type":"code","source":["# Fine-tuned된 데이터셋을 평가한다.\n","\n","def evaluate(model, tokenizer):\n","\"\"\"\n","Write your code here\n","\"\"\"\n","\n","\n","def main():\n","    # 모델 정의\n","    model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\", num_labels = 2).to(device)\n","    #model.load_state_dict(torch.load('models/squad_model.bin'))\n","    model.eval()\n","\n","    model.to(args.device)\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","    evaluate(model, tokenizer)"],"metadata":{"id":"7ODl70HH93fA"},"execution_count":null,"outputs":[]}]}